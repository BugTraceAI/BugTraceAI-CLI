import asyncio
from datetime import datetime
from bugtrace.agents.base import BaseAgent
from bugtrace.core.ui import dashboard
from bugtrace.memory.manager import memory_manager
from bugtrace.tools.exploitation.mutation import mutation_engine
from bugtrace.tools.external import external_tools
from bugtrace.core.config import settings
from bugtrace.core.llm_client import llm_client
from bugtrace.utils.logger import get_logger

# Import Conductor V2 for validation
from bugtrace.core.conductor import conductor

# Import Detectors (Check if they exist or mock if needed)
try:
    from bugtrace.tools.exploitation.xxe import xxe_detector
    from bugtrace.tools.exploitation.proto import proto_detector
    from bugtrace.tools.exploitation.csti import csti_detector
    from bugtrace.tools.exploitation.sqli import sqli_detector
    from bugtrace.tools.exploitation.header_injection import header_detector
except ImportError:
    # Safe fallback if some tools aren't fully modular yet
    pass

logger = get_logger("agents.exploit")

class ExploitAgent(BaseAgent):
    """
    Advanced Exploit Agent with 'Ladder Logic' (Light -> Heavy).
    Optimizes resources by running lightweight python-based checks first, 
    and only elevating to heavy tools (like SQLMap) when suspicious.
    
    EVENT BUS INTEGRATION (Phase 1 - COMPLETED):
    - Subscribes to: "new_input_discovered" (from ReconAgent)
    - Publishes: "vulnerability_detected" (to SkepticalAgent)
    """
    def __init__(self, event_bus=None):
        # Analysis-aware testing (Must be set BEFORE super().__init__ because _setup_event_subscriptions uses it)
        from bugtrace.core.config import settings
        self.use_analysis = getattr(settings, "ANALYSIS_ENABLE", True)
        self.confidence_threshold = getattr(settings, "ANALYSIS_CONFIDENCE_THRESHOLD", 0.7)
        self.analysis_reports = {}  # URL -> analysis report cache
        
        super().__init__("Exploit-1", "Offensive", event_bus=event_bus, agent_id="exploit_1")
        
        self.tested_vectors = set()
        self.mandatory_sqlmap = True  # Default mandatory SQLMap validation
        self.validated_findings = {"SQLi": set(), "XSS": set(), "Other": set()}  # Track validated params
    
    def _find_report_dir(self, url: str):
        """Find the most recent report directory for a given URL."""
        from pathlib import Path
        from urllib.parse import urlparse
        
        parsed = urlparse(url)
        # Fix for malformed URLs where query params might be appended without ?
        netloc = parsed.netloc
        if "&" in netloc and "?" not in url:
             netloc = netloc.split("&")[0]
             
        domain = netloc or "unknown"
        # CLEANUP: Remove port if present to match report dir format
        if ":" in domain:
            domain = domain.split(":")[0]
            
        domain = domain.replace('/', '_')
        
        reports_path = Path("reports")
        if not reports_path.exists():
            return None
        
        # Find all directories starting with this domain
        matching_dirs = [d for d in reports_path.iterdir() 
                        if d.is_dir() and d.name.startswith(domain + "_")]
        
        if not matching_dirs:
            return None
        
        # Return the most recent one (sorted by name which includes timestamp)
        return sorted(matching_dirs, reverse=True)[0]
    
    def _setup_event_subscriptions(self):
        """Subscribe to events from Event Bus."""
        if self.use_analysis:
            # Subscribe to analysis results (primary)
            self.event_bus.subscribe("url_analyzed", self.handle_url_analyzed)
            logger.info(f"[{self.name}] Subscribed to: url_analyzed (analysis-driven mode)")
        else:
            # Fallback to direct input discovery
            self.event_bus.subscribe("new_input_discovered", self.handle_new_input)
            logger.info(f"[{self.name}] Subscribed to: new_input_discovered (legacy mode)")
    
    def _cleanup_event_subscriptions(self):
        """Cleanup event subscriptions on agent stop."""
        if self.use_analysis:
            self.event_bus.unsubscribe("url_analyzed", self.handle_url_analyzed)
        else:
            self.event_bus.unsubscribe("new_input_discovered", self.handle_new_input)
        logger.info(f"[{self.name}] Unsubscribed from events")
    
    async def handle_new_input(self, data: dict):
        """
        EVENT HANDLER: Triggered when ReconAgent discovers new input.
        Executes IMMEDIATELY (~50ms) instead of polling (~10s).
        """
        # Extract event data
        url = data.get('url', '')
        input_details = data.get('input', {})
        input_label = input_details.get('name', 'unknown')
        input_type = input_details.get('type', '')
        
        logger.info(
            f"[{self.name}] üî• EVENT: new_input_discovered | "
            f"Input: {input_label} ({input_type}) at {url}"
        )
        
        # Deduplication check
        test_key = f"{url}:{input_label}"
        if test_key in self.tested_vectors:
            logger.debug(f"[{self.name}] Input already tested, skipping")
            return
        
        # Mark as tested
        self.tested_vectors.add(test_key)
        
        # Update dashboard
        dashboard.update_task(self.name, status=f"Event: Testing {input_label}")
        
        try:
            # 1. WAF Detection
            await self._check_waf(url)
            
            # 2. Check SAFE_MODE
            if settings.SAFE_MODE:
                logger.info(f"[{self.name}] SAFE MODE: Skipping {input_label}")
                return
            

            
            # 3. Run ladder logic based on input type
            if ("search" in url.lower() or "q=" in url or input_type == "text"):
                await self._ladder_ui_attacks(url, input_label)
            
            if ("id=" in url or "cat=" in url or input_type == "number"):
                await self._ladder_sqli(url)
            
            await self._ladder_infrastructure(url)
            
            logger.info(f"[{self.name}] ‚úÖ Completed testing {input_label}")
            
        except Exception as e:
            logger.error(f"[{self.name}] Handler error: {e}", exc_info=True)
    async def handle_url_analyzed(self, data: dict):
        """
        Handle url_analyzed event from AnalysisAgent.
        Reads analysis report and performs conditional exploitation.
        """
        report = data.get('report', {})
        url = report.get('url', '')
        
        if not url:
            logger.error(f"[{self.name}] No URL in analysis report")
            return
        
        logger.info(f"[{self.name}] üìä Analysis report received for {url}")
        
        # Get attack priority and skip tests from report
        attack_priority = report.get('attack_priority', [])
        skip_tests = report.get('skip_tests', [])
        consensus_vulns = report.get('consensus_vulns', [])
        
        logger.info(f"[{self.name}] Attack priority: {attack_priority}")
        logger.info(f"[{self.name}] Consensus vulns: {len(consensus_vulns)}")
        logger.info(f"[{self.name}] Skip tests: {skip_tests}")
        
        # Check if any high-confidence XSS detected
        xss_vulns = [v for v in consensus_vulns if 'XSS' in v.get('type', '').upper()]
        
        if xss_vulns:
            logger.info(f"[{self.name}] üéØ {len(xss_vulns)} XSS vulnerabilities to validate")
            await self._validate_xss_from_report(url, xss_vulns)
        
        # Check for SQLi
        sqli_vulns = [v for v in consensus_vulns if 'SQL' in v.get('type', '').upper()]
        
        if sqli_vulns and 'SQLi' in attack_priority:
            logger.info(f"[{self.name}] üéØ {len(sqli_vulns)} SQLi vulnerabilities to test")
            await self._ladder_sqli(url)
        
        logger.info(f"[{self.name}] ‚úÖ Completed conditional exploitation for {url}")
    
    async def _validate_xss_from_report(self, url: str, xss_vulns: list):
        """
        Validate XSS vulnerabilities using browser + vision model.
        Cost-conscious: Only validates with screenshots.
        
        IMPROVED: Uses actual parameter names from analysis locations.
        """
        from pathlib import Path
        from urllib.parse import urlparse, parse_qs, urlencode
        
        vision_calls = 0
        max_calls = getattr(settings, 'VALIDATION_MAX_VISION_CALLS_PER_URL', 3)
        
        # Standard XSS test parameters if no specific ones found
        fallback_params = ['searchFor', 'q', 'query', 'search', 'keyword', 'name', 'id', 'test']
        
        for vuln in xss_vulns:
            if vision_calls >= max_calls:
                logger.warning(f"[{self.name}] Max vision calls reached ({max_calls})")
                break
            
            vuln_type = vuln.get('type', 'XSS')
            confidence = vuln.get('confidence', 0.0)
            locations = vuln.get('locations', [])
            
            logger.info(f"[{self.name}] Testing {vuln_type} (confidence: {confidence})")
            logger.info(f"[{self.name}] Locations: {locations}")
            
            # Extract parameter names from locations
            param_names = []
            for loc in locations:
                loc_lower = str(loc).lower()
                # Try to extract param names from location text
                if 'searchfor' in loc_lower:
                    param_names.append('searchFor')
                if 'parameter' in loc_lower:
                    # Extract param name from "parameter 'xyz'"
                    import re
                    match = re.search(r"parameter['\s]+(\w+)", loc_lower)
                    if match:
                        param_names.append(match.group(1))
            
            # Use found params or fallback
            test_params = param_names if param_names else fallback_params[:3]
            
            # XSS Payloads to try (simple + encoded)
            payloads = [
                "<script>alert('XSS-TEST-BUGTRACE')</script>",
                "<img src=x onerror=alert('XSS-TEST')>",
                "'\"><script>alert('XSS')</script>"
            ]
            
            parsed = urlparse(url)
            base_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
            
            for param in test_params:
                for payload in payloads[:1]:  # Only test first payload per param (cost saving)
                    if vision_calls >= max_calls:
                        break
                    
                    # Build test URL with payload in actual param
                    test_url = f"{base_url}?{param}={payload}"
                    logger.info(f"[{self.name}] Testing XSS: {param}={payload[:30]}...")
                    
                    try:
                        # Use browser to test XSS
                        screenshot_path = await self._test_xss_with_browser(test_url, payload)
                        
                        if screenshot_path and Path(screenshot_path).exists():
                            # Validate with vision model
                            is_confirmed = await self._validate_xss_screenshot(screenshot_path)
                            vision_calls += 1
                            
                            if is_confirmed:
                                logger.info(f"[{self.name}] ‚úÖ XSS CONFIRMED on {param}!")
                                # Report finding
                                await self._report_finding(url, "XSS", confidence, screenshot_path, validated=True)
                                return  # Found it! Stop testing
                            else:
                                logger.info(f"[{self.name}] ‚ùå XSS not confirmed on {param}")
                        else:
                            logger.warning(f"[{self.name}] No screenshot captured for XSS test")
                            
                    except Exception as e:
                        logger.error(f"[{self.name}] XSS validation failed: {e}", exc_info=True)
            
            logger.info(f"[{self.name}] ‚ùå No XSS confirmed for this vulnerability")

    
    async def _test_xss_with_browser(self, url: str, payload: str) -> str:
        """
        Test XSS using browser and capture screenshot.
        Returns path to screenshot if alert is detected.
        """
        try:
            from bugtrace.tools.visual.browser import BrowserManager
            from pathlib import Path
            
            # Find report directory for this URL (most recent)
            report_dir = self._find_report_dir(url)
            if not report_dir:
                logger.error(f"[{self.name}] No report directory found for {url}")
                return None
            
            screenshots_dir = report_dir / "screenshots"
            screenshots_dir.mkdir(parents=True, exist_ok=True)
            
            browser = BrowserManager()
            
            # Use the robust verification method from BrowserManager
            # This handles starting the browser, context management, and dialog listening
            temp_screenshot, logs, triggered = await browser.verify_xss(url)
            
            if not temp_screenshot:
                logger.warning(f"[{self.name}] No screenshot captured from verify_xss")
                return None
                
            # Move screenshot to the correct report directory
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            final_path = screenshots_dir / f"xss_test_{timestamp}.png"
            
            # Copy/Move logic
            import shutil
            try:
                shutil.move(temp_screenshot, final_path)
            except Exception as e:
                logger.error(f"[{self.name}] Failed to move screenshot: {e}")
                # Fallback to temp path if move fails, but prefer report dir
                return temp_screenshot

            if triggered:
                logger.info(f"[{self.name}] üéâ Alert dialog detected via BrowserManager")
                return str(final_path)
            else:
                logger.info(f"[{self.name}] No alert dialog detected (Logs: {len(logs)})")
                return str(final_path)
                
        except Exception as e:
            logger.error(f"[{self.name}] Browser test failed: {e}")
            return None
    
    async def _validate_screenshot(self, screenshot_path: str, vuln_type: str = "XSS") -> bool:
        """
        Validate vulnerability using vision model (cost-conscious).
        
        CRITICAL: Uses vuln_type to ask the CORRECT question.
        - XSS: Looks for JavaScript alert() dialog box
        - SQLi: Looks for SQL error messages in the page
        - Generic: General vulnerability indicators
        
        Returns True if the expected vulnerability indicator is visible.
        """
        try:
            vision_enabled = getattr(settings, 'VALIDATION_VISION_ENABLED', True)
            if not vision_enabled:
                logger.info(f"[{self.name}] Vision validation disabled")
                return False
            
            # CRITICAL: Use vuln_type-specific prompts to avoid misclassification
            # XSS uses BUGTRACE marker for reliable detection (alert() can be sandboxed)
            prompts = {
                "XSS": (
                    "This is a browser screenshot. Look carefully at the page content. "
                    "Is there ANY of the following visible on this page? "
                    "1) Text containing 'BUGTRACE-XSS-CONFIRMED' or 'BUGTRACE-XSS' "
                    "2) A JavaScript alert popup/dialog box "
                    "3) Red colored text showing a domain name (like 'example.com') "
                    "4) Any text that looks like it was injected (unusual formatting, yellow background). "
                    "Answer ONLY: YES or NO"
                ),
                "SQLi": (
                    "This is a browser screenshot. Does this page show a SQL database error message? "
                    "Look for text like 'SQL syntax error', 'mysql', 'ORA-', 'PostgreSQL', 'SQLite', 'ODBC', "
                    "or stack traces mentioning database. Answer ONLY: YES or NO"
                ),
                "LFI": (
                    "This is a browser screenshot. Does this page show content from a local file "
                    "like /etc/passwd (showing root:x:0:0) or Windows system files? Answer ONLY: YES or NO"
                ),
                "GENERIC": (
                    "This is a browser screenshot. Does this page show any error message, "
                    "stack trace, or sensitive information disclosure? Answer ONLY: YES or NO"
                )
            }
            
            # Use external system_prompt if available as override/template
            prompt = prompts.get(vuln_type.upper(), prompts["GENERIC"])
            if self.system_prompt:
                # Use the template from the markdown file
                prompt = self.system_prompt.replace("{vuln_type}", vuln_type)
            
            logger.info(f"[{self.name}] Vision validation for {vuln_type}: {prompt[:60]}...")
            
            # Call LLM with image
            result = await llm_client.generate_with_image(
                prompt=prompt,
                image_path=screenshot_path,
                model_override=getattr(settings, 'VALIDATION_VISION_MODEL', 'qwen/qwen3-vl-8b-thinking'),
                module_name=f"ExploitAgent-Vision-{vuln_type}"
            )
            
            # Parse response - strict YES matching
            is_confirmed = result.strip().upper().startswith("YES")
            
            logger.info(f"[{self.name}] Vision validation ({vuln_type}): {is_confirmed}")
            logger.debug(f"[{self.name}] Vision response: {result}")
            
            return is_confirmed
            
        except Exception as e:
            logger.error(f"[{self.name}] Vision validation error: {e}")
            return False
    
    # Backward compatibility alias
    async def _validate_xss_screenshot(self, screenshot_path: str) -> bool:
        """Legacy XSS-specific validation. Calls generic validator with XSS type."""
        return await self._validate_screenshot(screenshot_path, "XSS")
    
    async def _report_finding(self, url: str, vuln_type: str, confidence: float, screenshot_path: str, validated: bool):
        """
        Report validated finding with proper structure.
        """
        from pathlib import Path
        import json
        
        # Find report directory for this URL
        report_dir = self._find_report_dir(url)
        if not report_dir:
            logger.error(f"[{self.name}] No report directory found for {url}")
            return
        
        finding = {
            "url": url,
            "type": vuln_type,
            "confidence": confidence,
            "screenshot": screenshot_path,
            "validated": validated,
            "timestamp": datetime.now().isoformat(),
            "validation_method": "vision_model" if validated else "browser_only"
        }
        
        # Load existing validated findings or create new
        findings_file = report_dir / "validated_findings.json"
        if findings_file.exists():
            with open(findings_file) as f:
                findings = json.load(f)
        else:
            findings = {"findings": [], "summary": {"total": 0, "validated": 0}}
        
        # Add new finding
        findings["findings"].append(finding)
        findings["summary"]["total"] = len(findings["findings"])
        findings["summary"]["validated"] = sum(1 for f in findings["findings"] if f["validated"])
        
        # Save
        with open(findings_file, "w") as f:
            json.dump(findings, f, indent=2)
        
        # Emit event
        await self.event_bus.emit("vulnerability_confirmed", finding)
        
        logger.info(f"[{self.name}] üìù Finding saved: {vuln_type} at {url}")
        logger.info(f"[{self.name}] üì∏ Screenshot: {screenshot_path}")
        logger.info(f"[{self.name}] ‚úÖ Validated: {validated}")

    async def run_loop(self):
        """
        DUAL MODE RUN LOOP (Polling + Events for safety).
        
        TODO: After confirming events work, remove polling block.
        """
        dashboard.log(f"[{self.name}] Agent Online. Dual Mode (Polling + Events).", "INFO")
        logger.info(f"[{self.name}] Started - Listening for events...")
        
        while self.running:
            await self.check_pause()
            
            # Poll Memory for new targets (LEGACY - Will be removed)
            attack_surface = memory_manager.get_attack_surface()
            
            # Filter targets
            pending_targets = []
            for n in attack_surface:
                 has_url = n.get('url') or n.get('properties', {}).get('url')
                 if n.get('label') not in self.tested_vectors and has_url:
                     pending_targets.append(n)
            
            if not pending_targets:
                if  datetime.now().second % 10 == 0:
                     dashboard.update_task(self.name, status="Listening...")
                await asyncio.sleep(2)
                continue
                
            dashboard.log(f"[{self.name}] Engaged {len(pending_targets)} targets (polling).", "INFO")
            
            for target in pending_targets:
                await self.check_pause()
                if not self.running: break
                
                label = target.get('label', 'Unknown')
                url = target.get('url') or target.get('properties', {}).get('url')
                if not url: 
                    continue 

                node_type = target.get('type', 'Unknown')
                
                self.tested_vectors.add(label)
                
                dashboard.update_task(self.name, status=f"Polling: {label}")
                
                try:
                    await self._check_waf(url)
                    
                    if settings.SAFE_MODE:
                        dashboard.log(f"[{self.name}] SAFE MODE: Skipping {label}", "WARN")
                        continue

                    # Skip XSS in polling when using analysis-driven mode
                    # XSS validation is handled by event-driven flow via _validate_xss_from_report
                    if not self.use_analysis:
                        if "xss" in label.lower() or "search" in url or node_type == "Input":
                            await self._ladder_ui_attacks(url, label)

                    if "sqli" in label.lower() or "id=" in url or node_type == "Input":
                        await self._ladder_sqli(url)
                        
                    await self._ladder_infrastructure(url)

                except Exception as e:
                    logger.error(f"Error exploiting {url}: {e}")
                
                await asyncio.sleep(1)
                
            await asyncio.sleep(5)

    async def _check_waf(self, url: str):
        """Checks for WAF presence."""
        pass


    async def _run_light_sqli_check(self, url: str) -> Optional[Tuple[str, Optional[str]]]:
        """Run lightweight SQLi detection."""
        try:
            return await sqli_detector.check(url)
        except Exception as e:
            logger.warning(f"SQLi Light Check failed: {e}")
            return None

    def _build_sqli_finding(self, url: str, msg: str, screenshot: Optional[str]) -> Dict:
        """Build SQLi finding data structure."""
        return {
            "finding_id": f"sqli_{url}",
            "type": "SQLi",
            "url": url,
            "payload": msg,
            "confidence": 0.9,
            "evidence": {
                "error_message": msg,
                "screenshot": screenshot,
                "response": {
                    "status_code": 500,
                    "body": msg,
                    "headers": {}
                }
            },
            "description": f"SQL Injection vulnerability detected via error-based technique. The server returned a database error message indicating injectable parameter. Error: {msg[:200]}",
            "reproduction": f"# SQLi detected at: {url}\n# Use sqlmap for full exploitation:\nsqlmap -u \"{url}\" --batch --dbs",
            "detected_by": self.name,
            "timestamp": datetime.now().isoformat()
        }

    async def _validate_and_emit_sqli(self, finding_data: Dict, url: str, msg: str) -> bool:
        """Validate SQLi finding with Conductor and emit event."""
        # VALIDATION: Check with Conductor V2
        is_valid, reason = conductor.validate_finding(finding_data)

        if not is_valid:
            logger.warning(f"[{self.name}] SQLi finding BLOCKED by validation: {reason}")
            dashboard.log(f"[{self.name}] SQLi blocked: {reason}", "WARN")
            return False

        # Validation passed - emit event
        dashboard.add_finding("SQL Injection", msg, "CRITICAL")
        logger.info(f"[{self.name}] SQLi CONFIRMED (validated): {msg}")

        memory_manager.add_node("FindingCandidate", finding_data["finding_id"], {
            "url": url, "payload": msg, "status": "FIRED", "type": "SQLi"
        })

        # Mark param as validated
        self._mark_param_validated(url, "SQLi")

        # EVENT: Emit vulnerability_detected
        await self.event_bus.emit("vulnerability_detected", finding_data)
        logger.info(f"[{self.name}] üì¢ EVENT EMITTED: vulnerability_detected (SQLi - validated)")

        return True

    def _mark_param_validated(self, url: str, vuln_type: str):
        """Mark a parameter as validated for a vulnerability type."""
        from urllib.parse import urlparse, parse_qs
        parsed = urlparse(url)
        params = list(parse_qs(parsed.query).keys()) if parsed.query else ["path"]
        param_key = f"{parsed.netloc}:{params[0] if params else 'unknown'}"

        self.validated_findings[vuln_type].add(param_key)
        logger.critical(f"[{self.name}] üéØ {vuln_type} VALIDATED on {param_key} - stopping {vuln_type} tests on this param")

    async def _run_sqlmap_validation(self, url: str) -> bool:
        """Run SQLMap for mandatory validation."""
        if "?" not in url or "=" not in url:
            return False

        if not self.mandatory_sqlmap:
            logger.warning(f"[{self.name}] ‚ö†Ô∏è Skipping SQLMap (MANDATORY_SQLMAP_VALIDATION=False)")
            return False

        dashboard.update_task(self.name, status=f"SQLi Heavy: SQLMap on {url}")

        from bugtrace.tools.visual.browser import browser_manager
        session_data = await browser_manager.get_session_data()
        cookies = session_data.get("cookies", [])

        logger.info(f"[{self.name}] üîç MANDATORY SQLMap validation: {url}")
        return await external_tools.run_sqlmap(url, cookies=cookies)

    async def _ladder_sqli(self, url: str):
        """
        SQLi Ladder:
        1. Light Check (Python Detector)
        2. Heavy Check (SQLMap) - Only if suspicious.
        """
        dashboard.update_task(self.name, status=f"SQLi Ladder: {url}")

        # Step 1: Light Check
        res_tuple = await self._run_light_sqli_check(url)
        if res_tuple:
            msg, screenshot = res_tuple if isinstance(res_tuple, tuple) else (res_tuple, None)
            finding_data = self._build_sqli_finding(url, msg, screenshot)

            if await self._validate_and_emit_sqli(finding_data, url, msg):
                return  # Stop testing THIS param for SQLi (not entire scan)
            
        # Step 2: Heavy Check (SQLMap) - MANDATORY if configured
        is_vuln = await self._run_sqlmap_validation(url)
        if not is_vuln:
            if "?" in url and "=" in url and self.mandatory_sqlmap:
                logger.info(f"[{self.name}] ‚ùå SQLMap rejected - false positive discarded")
            return  # Not vulnerable

        # SQLMap CONFIRMED - create finding
        self._mark_param_validated(url, "SQLi")

        finding_data = {
            "finding_id": f"sqli_map_{url}",
            "type": "SQLi",
            "url": url,
            "payload": "SQLMap Confirmed",
            "confidence": 1.0,
            "evidence": {
                "error_message": "SQLMap confirmed vulnerability",
                "response": {
                    "status_code": 200,
                    "body": "SQLMap output",
                    "headers": {}
                }
            },
            "description": f"SQL Injection vulnerability confirmed by SQLMap automated scanner. Full database enumeration and data extraction is possible.",
            "reproduction": f"sqlmap -u \"{url}\" --batch --dbs --tables",
            "detected_by": self.name,
            "timestamp": datetime.now().isoformat()
        }

        # Validate and emit
        if not await self._validate_and_emit_sqli(finding_data, url, "SQLMap confirmed"):
            return

        # Additional event emission for SQLMap
        await self.event_bus.emit("vulnerability_detected", finding_data)
        logger.info(f"[{self.name}] üì¢ EVENT EMITTED: vulnerability_detected (SQLMap - validated)")

    async def _ladder_ui_attacks(self, url: str, label: str):
        """UI Attacks Ladder (XSS, CSTI) with Conductor V2 validation."""
        dashboard.update_task(self.name, status=f"XSS Ladder: {url}")
        
        # 1. Mutation Engine for XSS
        base_payload = "<script>alert(document.domain)</script>"
        mutated = await mutation_engine.mutate_payload(base_payload, f"Target: {url}")
        
        # VALIDATION PRE-CHECK: Validate payload before testing
        if not conductor.validate_payload(mutated, "XSS"):
            logger.warning(f"[{self.name}] XSS payload INVALID: {mutated[:50]}")
            return
        
        # Prepare finding data
        finding_data = {
            "finding_id": f"xss_{label}",
            "type": "XSS",
            "url": url,
            "payload": mutated,
            "confidence": 0.7,
            "evidence": {
                "alert_triggered": True,  # Assume for now (SkepticalAgent will verify)
                "screenshot": None,  # Will be captured by SkepticalAgent
                "response": {
                    "status_code": 200,
                    "body": "",
                    "headers": {}
                }
            },
            "description": f"Cross-Site Scripting (XSS) vulnerability detected. Payload was reflected or executed in the page context. Payload: {mutated[:100]}",
            "reproduction": f"# Open in browser with payload:\n{url}",
            "detected_by": self.name,
            "timestamp": datetime.now().isoformat()
        }
        
        # VALIDATION: Check with Conductor V2
        is_valid, reason = conductor.validate_finding(finding_data)
        
        if not is_valid:
            logger.warning(f"[{self.name}] XSS finding BLOCKED: {reason}")
            dashboard.log(f"[{self.name}] XSS blocked: {reason}", "WARN")
            return
        
        # Validation passed - store and emit
        memory_manager.add_node("FindingCandidate", f"xss_{label}", {
            "url": url, "payload": mutated, "status": "TO_VERIFY", "type": "XSS"
        })
        
        # EVENT: Emit vulnerability_detected
        await self.event_bus.emit("vulnerability_detected", finding_data)
        logger.info(f"[{self.name}] üì¢ EVENT EMITTED: vulnerability_detected (XSS - validated)")
        
        # 2. CSTI Check
        res = await csti_detector.check(url)
        if res:
             dashboard.add_finding("CSTI", res, "HIGH")

    async def _ladder_infrastructure(self, url: str):
        """Infrastructure Ladder (Headers, Proto, XXE)."""
        # Header Injection
        res = await header_detector.check(url)
        if res:
            msg = res[0] if isinstance(res, tuple) else res
            dashboard.add_finding("Header Injection", msg, "MEDIUM")

        # Prototype Pollution
        res = await proto_detector.check(url)
        if res:
             dashboard.add_finding("Prototype Pollution", res, "HIGH")
