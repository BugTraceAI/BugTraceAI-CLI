"""
AgenticValidator: AI-Powered Vulnerability Validation Agent (v2 - OPTIMIZED)

PERFORMANCE OPTIMIZATIONS (2026-01-21):
1. Parallel validation with configurable concurrency (3x-5x faster)
2. Browser session pooling (reuse instead of launch per validation)
3. Early-exit when CDP confirms (skip expensive vision API)
4. Result caching for similar payloads/URLs (avoid re-validation)
5. Smart fast-path for high-confidence/pre-validated findings
6. Reduced timeouts and eliminated unnecessary sleeps
7. Batch screenshot capture for similar URLs

This validator uses an LLM with vision capabilities to:
1. Navigate to target URLs with payloads
2. Capture screenshots
3. Reason about the visual state to determine if vulnerability is real
4. Adapt testing strategy based on context
"""

from typing import List, Dict, Any, Tuple, Optional, Set
import asyncio
import base64
import json
import hashlib
import time
from pathlib import Path
from loguru import logger
from dataclasses import dataclass, field
from collections import OrderedDict

from bugtrace.agents.base import BaseAgent
from bugtrace.tools.visual.browser import browser_manager, BrowserManager
from bugtrace.tools.visual.verifier import XSSVerifier, VerificationResult
from bugtrace.core.ui import dashboard
from bugtrace.core.config import settings
from bugtrace.core.llm_client import llm_client
# NOTE: ValidationFeedback imports removed - feedback loop eliminated for simplicity
# AgenticValidator is now a linear CDP specialist (no loopback to specialist agents)


# =============================================================================
# OPTIMIZATION 1: Validation Result Cache (LRU)
# =============================================================================
@dataclass
class ValidationCache:
    """LRU Cache for validation results to avoid re-validating identical payloads."""
    max_size: int = 100
    _cache: OrderedDict = field(default_factory=OrderedDict)

    def get_key(self, url: str, payload: str) -> str:
        """Generate cache key from full URL + payload hash.

        NOTE: We include the full URL (with query params) because different
        parameter values may have different escaping/filtering behavior.
        E.g., /user?id=1 vs /user?id=100 might have different XSS contexts.
        """
        from urllib.parse import urlparse, parse_qs, urlencode
        parsed = urlparse(url)
        # Sort query params for consistent caching
        params = parse_qs(parsed.query, keep_blank_values=True)
        sorted_query = urlencode(sorted(params.items()), doseq=True) if params else ""
        normalized_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{sorted_query}" if sorted_query else f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
        content = f"{normalized_url}:{payload or 'none'}"
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, url: str, payload: str) -> Optional[Dict]:
        """Get cached result if exists."""
        key = self.get_key(url, payload)
        if key in self._cache:
            self._cache.move_to_end(key)  # LRU: move to end
            logger.debug(f"Cache HIT for {url[:50]}...")
            return self._cache[key]
        return None

    def set(self, url: str, payload: str, result: Dict):
        """Cache a validation result."""
        key = self.get_key(url, payload)
        self._cache[key] = result
        self._cache.move_to_end(key)
        # Evict oldest if over capacity
        while len(self._cache) > self.max_size:
            self._cache.popitem(last=False)

    def clear(self):
        self._cache.clear()

    def __len__(self):
        return len(self._cache)


# =============================================================================
# OPTIMIZATION 2: Shared XSSVerifier Pool
# =============================================================================
class VerifierPool:
    """Pool of XSSVerifier instances to avoid recreation overhead."""

    def __init__(self, pool_size: int = 3):
        self.pool_size = pool_size
        self._verifiers: List[XSSVerifier] = []
        self._semaphore: Optional[asyncio.Semaphore] = None
        self._initialized = False

    async def initialize(self):
        """Initialize verifier pool (lazy init)."""
        if self._initialized:
            return
        self._semaphore = asyncio.Semaphore(self.pool_size)
        self._verifiers = [
            XSSVerifier(headless=settings.HEADLESS_BROWSER, prefer_cdp=False)
            for _ in range(self.pool_size)
        ]
        self._initialized = True
        logger.info(f"VerifierPool initialized with {self.pool_size} instances")

    async def get_verifier(self) -> XSSVerifier:
        """Get an available verifier from the pool."""
        if not self._initialized:
            await self.initialize()
        await self._semaphore.acquire()
        # Return any verifier (they're stateless between calls)
        return self._verifiers[0]

    def release(self):
        """Release verifier back to pool."""
        if self._semaphore:
            self._semaphore.release()


# Global pool instance
_verifier_pool = VerifierPool(pool_size=3)


class AgenticValidator(BaseAgent):
    """
    An AI-powered validator that uses vision + reasoning to validate vulnerabilities.

    v2 OPTIMIZATIONS:
    - Parallel batch validation (configurable concurrency)
    - Result caching for identical URL+payload combinations
    - Early-exit when CDP confirms (skips expensive vision API)
    - Browser session reuse via VerifierPool
    - Smart filtering of pre-validated and low-severity findings

    Unlike the basic ValidatorAgent which just checks for alert(), this agent:
    - Takes screenshots and sends them to a vision LLM
    - Asks the LLM to reason about what it sees
    - Can adapt its testing strategy based on the response
    - Provides detailed evidence with confidence scores
    """

    # Configuration
    MAX_CONCURRENT_VALIDATIONS = 3  # Parallel browser sessions
    SKIP_VISION_ON_CDP_CONFIRM = True  # Early exit optimization
    ENABLE_CACHE = True  # Result caching
    FAST_VALIDATION_TIMEOUT = 30.0  # Reduced from default
    MAX_TOTAL_VALIDATION_TIME = 600.0  # 10 minutes global timeout (was 300s - too aggressive)
    MAX_FEEDBACK_DEPTH = 2  # Maximum recursion depth for feedback loop

    def __init__(self, event_bus=None, cancellation_token=None):
        super().__init__("AgenticValidator", "AI Vision Validator", event_bus, agent_id="agentic_validator")
        self.max_retries = 3
        self.validation_prompts = self._load_prompts()
        
        # Cancellation token for graceful shutdown (injected from orchestrator)
        self._cancellation_token = cancellation_token or {"cancelled": False}

        # OPTIMIZATION: Validation cache
        self._cache = ValidationCache(max_size=150)

        # OPTIMIZATION: Concurrency semaphore for parallel validation
        self._validation_semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_VALIDATIONS)

        # Statistics tracking
        self._stats = {
            "total_validated": 0,
            "cache_hits": 0,
            "cdp_confirmed": 0,
            "vision_analyzed": 0,
            "skipped_prevalidated": 0,
            "avg_time_ms": 0,
            "total_time_ms": 0
        }

        # NOTE: Feedback loop removed - AgenticValidator is now a linear CDP specialist
        # No loopback to XSSAgent/CSTIAgent - validation is single-attempt
        self.llm_client = llm_client
        
    def _load_prompts(self) -> Dict[str, str]:
        """Load specialized prompts for different vulnerability types."""
        prompts = {
            "xss": self._get_xss_prompt(),
            "sqli": self._get_sqli_prompt(),
            "general": self._get_general_prompt()
        }

        # Override with custom prompts if provided
        if self.system_prompt:
            self._apply_custom_prompts(prompts)

        return prompts

    def _get_xss_prompt(self) -> str:
        """Get XSS validation prompt template."""
        return """You are a security expert analyzing a screenshot for XSS vulnerability validation.

CONTEXT:
- BugTraceAI security scanner found a potential XSS vulnerability
- We injected a test payload that creates a visual banner or triggers an alert
- Our payloads create text containing: "HACKED BY BUGTRACEAI", "FRAGMENT XSS", "MXSS DETECTED", or trigger alert dialogs

TASK:
Look at this screenshot and determine if the XSS was successful.

SUCCESS indicators (HIGH CONFIDENCE - mark success=true):
1. ANY text containing "HACKED", "BUGTRACEAI", "BUGTRACE", "PWNED", "XSS" appearing on the page (banner, div, any element)
2. A browser alert/confirm/prompt dialog box (usually a small popup with OK button)
3. Red or colored banner at top/bottom of page with security-related text
4. Text like "FRAGMENT XSS" or "MXSS DETECTED" visible anywhere

MEDIUM CONFIDENCE indicators (mark success=true, confidence=0.7):
1. Unusual HTML elements that look injected (e.g., floating divs, unexpected banners)
2. JavaScript code visible as rendered content (not escaped)
3. Page layout disruption suggesting DOM manipulation

FAILURE indicators (mark success=false):
1. Normal page content with no abnormalities
2. Error message like "Invalid input" or "Not found"
3. The payload is visible as escaped text (e.g., "&lt;script&gt;" shown literally)
4. WAF/security block page ("Request blocked", "Forbidden")

IMPORTANT: If you see ANY text containing "HACKED" or "BUGTRACEAI" or "XSS" that wasn't part of the original page content, this is SUCCESS - our payload executed.

Respond in JSON format:
{
    "success": true/false,
    "confidence": 0.0-1.0,
    "evidence": "description of what you see that proves/disproves XSS",
    "recommendation": "next steps if any"
}"""

    def _get_sqli_prompt(self) -> str:
        """Get SQL Injection validation prompt template."""
        return """You are a security expert analyzing a screenshot for SQL Injection validation.

CONTEXT:
- A security scanner found a potential SQL Injection vulnerability
- We injected a test payload into the page
- Look for signs of SQL error messages or data exfiltration

SUCCESS indicators:
1. SQL error messages (MySQL, PostgreSQL, MSSQL syntax errors)
2. Database version disclosure
3. Unexpected data being displayed
4. "You have an error in your SQL syntax" message
5. Column/table names visible in error

FAILURE indicators:
1. Normal page with expected content
2. Generic "Invalid input" error (input validation, not SQLi)
3. WAF block page
4. HTTP 500 with no SQL-related info

Respond in JSON format:
{
    "success": true/false,
    "confidence": 0.0-1.0,
    "evidence": "description of what you see",
    "sql_error_type": "MySQL/PostgreSQL/MSSQL/None",
    "recommendation": "next steps"
}"""

    def _get_general_prompt(self) -> str:
        """Get general vulnerability validation prompt template."""
        return """You are a security expert analyzing a screenshot for vulnerability validation.

Examine the screenshot and determine if there are any signs of:
1. Security vulnerability exploitation
2. Error messages revealing sensitive information
3. Unexpected behavior that indicates a vulnerability
4. WAF/security tool blocking

Respond in JSON format:
{
    "anomaly_detected": true/false,
    "confidence": 0.0-1.0,
    "description": "what you observe",
    "security_implications": "potential impact if any"
}"""

    def _apply_custom_prompts(self, prompts: Dict[str, str]):
        """Override default prompts with custom ones from system_prompt."""
        import re
        parts = re.split(r'#+\s+', self.system_prompt)

        for part in parts:
            self._process_prompt_section(part, prompts)

    def _process_prompt_section(self, part: str, prompts: Dict[str, str]):
        """Process a single prompt section and update prompts dict."""
        import re
        part_lower = part.lower()

        # Guard: XSS validation prompt
        if part_lower.startswith("xss validation prompt"):
            prompts["xss"] = re.sub(r'^xss validation prompt\s*', '', part, flags=re.IGNORECASE).strip()
            return

        # Guard: SQLi validation prompt
        if part_lower.startswith("sqli validation prompt"):
            prompts["sqli"] = re.sub(r'^sqli validation prompt\s*', '', part, flags=re.IGNORECASE).strip()
            return

        # Guard: General validation prompt
        if part_lower.startswith("general validation prompt"):
            prompts["general"] = re.sub(r'^general validation prompt\s*', '', part, flags=re.IGNORECASE).strip()
            return
    
    async def run_loop(self):
        """Typically triggered by orchestrator, not continuous."""
        pass
    
    async def validate_with_vision(
        self, 
        finding: Dict[str, Any],
        screenshot_path: str
    ) -> Dict[str, Any]:
        """
        Use a vision LLM to analyze the screenshot and validate the finding.
        """
        vuln_type = self._detect_vuln_type(finding)
        prompt = self.validation_prompts.get(vuln_type, self.validation_prompts["general"])
        
        try:
            # Call vision model
            response = await self._call_vision_model(prompt, screenshot_path)
            result = self._parse_vision_response(response)
            
            finding["validated"] = result.get("success", False)
            finding["confidence"] = result.get("confidence", 0.0)
            finding["reasoning"] = result.get("evidence", "No clear evidence found in screenshot.")
            finding["validator_notes"] = response # Store full LLM reasoning
            
            if finding["validated"]:
                self.think(f"âœ… CONFIRMED: {finding.get('url')} (confidence: {result.get('confidence')})")
            else:
                self.think(f"âŒ Could not confirm via vision: {finding.get('url')}")
                
        except Exception as e:
            logger.error(f"Vision validation failed: {e}", exc_info=True)
            finding["validated"] = False
            finding["reasoning"] = f"Vision validation error: {str(e)}"
            
        return finding
    
    def _agentic_prepare_context(self, finding: Dict[str, Any]) -> Tuple[str, Optional[str], str]:
        """Prepare validation context from finding."""
        url = finding.get("url")
        payload = finding.get("payload")
        vuln_type = self._detect_vuln_type(finding)

        # Select best verification URL from specialist methods if available
        if finding.get("verification_methods"):
            url, payload = self._select_best_verification_method(finding, url)

        return url, payload, vuln_type

    def _select_best_verification_method(self, finding: Dict, url: str) -> Tuple[str, Optional[str]]:
        """Select best verification method from specialist options."""
        preferred = ["console_log", "window_variable", "dom_modification"]
        for p_type in preferred:
            for m in finding.get("verification_methods", []):
                if m.get("type") == p_type and m.get("url_encoded"):
                    logger.info(f"Using specialized verification method: {p_type}")
                    return m.get("url_encoded"), None
        return url, finding.get("payload")

    async def _agentic_execute_validation(
        self, url: str, payload: Optional[str], vuln_type: str
    ) -> Tuple[Optional[str], List[str], bool]:
        """Execute payload with timeout and return results."""
        try:
            return await asyncio.wait_for(
                self._execute_payload_optimized(url, payload, vuln_type),
                timeout=self.FAST_VALIDATION_TIMEOUT
            )
        except asyncio.TimeoutError:
            logger.warning(f"Validation timeout for {url[:50]}...")
            return None, ["TIMEOUT"], False

    def _agentic_build_cdp_result(
        self, logs: List[str], url: str, payload: Optional[str], start_time: float
    ) -> Dict[str, Any]:
        """Build result dict for CDP confirmation."""
        self._stats["cdp_confirmed"] += 1
        result = {
            "validated": True,
            "status": "VALIDATED_CONFIRMED",
            "reasoning": f"Execution CONFIRMED: Low-level event (alert/dialog) triggered. Logs: {logs}",
            "screenshot_path": None,
            "logs": logs
        }

        if self.ENABLE_CACHE:
            self._cache.set(url, payload, result)

        elapsed = (time.time() - start_time) * 1000
        self._update_stats(elapsed)
        logger.info(f"âš¡ CDP confirmed in {elapsed:.0f}ms (skipped vision API)")
        return result

    async def _agentic_analyze_with_vision(
        self, finding: Dict, screenshot_path: str, logs: List[str]
    ) -> Dict[str, Any]:
        """Analyze screenshot with vision and build result."""
        self.think("CDP silent. Invoking Vision Analysis...")
        self._stats["vision_analyzed"] += 1

        vision_result = await self.validate_with_vision(finding, screenshot_path)
        confidence = vision_result.get("confidence", 0.0)
        validated = vision_result.get("validated", False)

        result = {"validated": False, "screenshot_path": screenshot_path, "logs": logs}

        if validated:
            result["validated"] = True
            result["status"] = "VALIDATED_CONFIRMED"
            result["reasoning"] = vision_result.get("reasoning", "Validated via vision analysis.")
        elif confidence >= 0.7:
            result["status"] = "MANUAL_REVIEW_RECOMMENDED"
            result["needs_manual_review"] = True
            result["reasoning"] = self._generate_manual_review_brief(finding, vision_result, logs)
            self.think(f"âš ï¸ SUSPICIOUS ({confidence:.0%}) - flagging for manual review")
        else:
            result["status"] = "VALIDATED_FALSE_POSITIVE"
            result["reasoning"] = vision_result.get("reasoning", "No evidence of execution found.")

        return result

    def _agentic_check_cache(self, url: str, payload: Optional[str]) -> Optional[Dict[str, Any]]:
        """Check cache for existing result."""
        if not self.ENABLE_CACHE:
            return None
        cached = self._cache.get(url, payload)
        if cached:
            self._stats["cache_hits"] += 1
            logger.info(f"ðŸš€ Cache hit for {url[:50]}... (skipping validation)")
        return cached

    async def _agentic_process_validation_result(
        self, screenshot_path: Optional[str], logs: List[str], basic_triggered: bool,
        finding: Dict, url: str, payload: Optional[str], start_time: float
    ) -> Dict[str, Any]:
        """Process validation result and build final response."""
        # Handle timeout
        if screenshot_path is None and logs == ["TIMEOUT"]:
            return {
                "validated": False,
                "reasoning": f"Validation timed out after {self.FAST_VALIDATION_TIMEOUT}s",
                "screenshot_path": None,
                "logs": ["TIMEOUT"]
            }

        # Early exit on CDP confirmation
        if basic_triggered:
            return self._agentic_build_cdp_result(logs, url, payload, start_time)

        # Visual analysis
        if screenshot_path and Path(screenshot_path).exists():
            result = await self._agentic_analyze_with_vision(finding, screenshot_path, logs)
        else:
            result = {
                "validated": False,
                "status": "VALIDATED_FALSE_POSITIVE",
                "reasoning": "Audit failed: Could not capture screenshot.",
                "screenshot_path": None,
                "logs": logs
            }

        # Cache and update stats
        if self.ENABLE_CACHE:
            self._cache.set(url, payload, result)
        elapsed = (time.time() - start_time) * 1000
        self._update_stats(elapsed)

        return result

    async def validate_finding_agentically(
        self,
        finding: Dict[str, Any],
        _recursion_depth: int = 0
    ) -> Dict[str, Any]:
        """
        V3 Reproduction Flow (Auditor Role) - OPTIMIZED.
        Validates findings using CDP events and vision analysis.
        """
        # Check for cancellation
        if self._cancellation_token.get("cancelled", False):
            return {"validated": False, "reasoning": "Validation cancelled by user"}

        # Prevent infinite recursion
        if _recursion_depth >= self.MAX_FEEDBACK_DEPTH:
            logger.warning(f"Max feedback depth ({self.MAX_FEEDBACK_DEPTH}) reached, stopping recursion")
            return {"validated": False, "reasoning": "Max feedback retries exceeded"}

        start_time = time.time()
        url, payload, vuln_type = self._agentic_prepare_context(finding)

        if not url:
            return {"validated": False, "reasoning": "Missing target URL"}

        # Check cache
        cached = self._agentic_check_cache(url, payload)
        if cached:
            return cached

        self.think(f"Auditing {vuln_type} on {url}")

        # Execute validation with semaphore
        async with self._validation_semaphore:
            screenshot_path, logs, basic_triggered = await self._agentic_execute_validation(
                url, payload, vuln_type
            )

            return await self._agentic_process_validation_result(
                screenshot_path, logs, basic_triggered, finding, url, payload, start_time
            )

    def _update_stats(self, elapsed_ms: float):
        """Update validation statistics."""
        self._stats["total_validated"] += 1
        self._stats["total_time_ms"] += elapsed_ms
        self._stats["avg_time_ms"] = self._stats["total_time_ms"] / self._stats["total_validated"]

    def get_stats(self) -> Dict[str, Any]:
        """Get validation statistics for reporting."""
        return {
            **self._stats,
            "cache_size": len(self._cache)
        }

    async def _execute_payload_optimized(
        self,
        url: str,
        payload: Optional[str],
        vuln_type: str
    ) -> Tuple[str, List[str], bool]:
        """
        OPTIMIZED payload execution using pooled verifiers.
        """
        if vuln_type == "xss":
            # Use pooled verifier instead of creating new one each time
            verifier = await _verifier_pool.get_verifier()
            try:
                target_url = self._construct_payload_url(url, payload)
                result = await verifier.verify_xss(
                    target_url,
                    screenshot_dir=str(settings.LOG_DIR),
                    timeout=self.FAST_VALIDATION_TIMEOUT - 5  # Leave margin
                )
                return result.screenshot_path, result.console_logs or [], result.success
            finally:
                _verifier_pool.release()
        else:
            return await self._generic_capture(url, payload)

    # NOTE: _has_specialist_authority removed - filtering now happens at ValidationEngine level

    def _generate_manual_review_brief(self, finding: Dict, vision_result: Dict, browser_logs: List) -> str:
        """Constructs a detailed explanation for manual triagers."""
        url = finding.get("url", "N/A")
        param = finding.get("parameter", "N/A")
        payload = finding.get("payload", "N/A")
        vision_evidence = vision_result.get("evidence", "No evidence provided by vision model.")
        confidence = vision_result.get("confidence", 0.0)
        
        brief = [
            "### ðŸ”Ž DETAILED MANUAL REVIEW BRIEF",
            f"**Target:** {url}",
            f"**Parameter:** `{param}`",
            f"**Payload:** `{payload}`",
            "",
            "#### ðŸ•µï¸ HUNTER OBSERVATIONS",
            "- Reflection detected in raw HTML (possible decoded or mutated form).",
            "- WAF presence suspected or bypass attempts initiated.",
            "",
            "#### ðŸ¤– AUDITOR (AGENTIC) AUDIT",
            f"- **Vision Confidence:** {confidence:.0%}",
            f"- **Execution Events (CDP):** {'None' if not browser_logs else f'Detected {len(browser_logs)} events'}",
            f"- **Vision Analysis:** {vision_evidence}",
            "",
            "#### ðŸ› ï¸ WHAT TO LOOK FOR (MANUAL CHECK)",
            "1. Open the target URL with the payload.",
            "2. Check if a **RED BANNER** with text **'HACKED BY BUGTRACEAI'** appears at the top.",
            "3. Check the Browser Console for successful `fetch` requests or execution logs.",
            "",
            "#### â“ WHY MANUAL REVIEW?",
            "Automatic validation is inconclusive because " + 
            ("the Vision AI detected a potential anomaly but no low-level protocol event (like an alert) was captured." if confidence >= 0.7 
             else "there is a strong indicator of vulnerability (reflection) but visual proof is obscured or non-standard.")
        ]
        return "\n".join(brief)
    
    async def _execute_payload(
        self, 
        url: str, 
        payload: Optional[str],
        vuln_type: str
    ) -> Tuple[str, List[str], bool]:
        """
        Execute the payload in browser and capture result.
        Returns (screenshot_path, logs, basic_triggered)
        """
        if vuln_type == "xss":
            # Use Playwright for current environment stability
            verifier = XSSVerifier(headless=settings.HEADLESS_BROWSER, prefer_cdp=False)
            target_url = self._construct_payload_url(url, payload)
            
            result = await verifier.verify_xss(target_url, screenshot_dir=str(settings.LOG_DIR))
            return result.screenshot_path, result.console_logs, result.success
        else:
            # Generic page capture for other types
            return await self._generic_capture(url, payload)
    
    def _check_sql_errors(self, content: str) -> Optional[str]:
        """Check page content for SQL error indicators. Returns error name if found."""
        sql_errors = [
            "SQL syntax",
            "mysql_",
            "ORA-",
            "PostgreSQL",
            "SQLITE_ERROR",
            "Microsoft SQL Server"
        ]

        content_lower = content.lower()
        for error in sql_errors:
            if error.lower() in content_lower:
                return error
        return None

    async def _generic_capture(
        self,
        url: str,
        payload: Optional[str]
    ) -> Tuple[str, List[str], bool]:
        """
        Generic page capture for non-XSS validations.
        """
        logs = []
        screenshot_path = ""

        target_url = self._construct_payload_url(url, payload) if payload else url

        async with browser_manager.get_page() as page:
            try:
                await page.goto(target_url, wait_until="domcontentloaded", timeout=30000)
                await page.wait_for_timeout(2000)

                import uuid
                screenshot_path = str(settings.LOG_DIR / f"validate_{uuid.uuid4().hex[:8]}.png")
                await page.screenshot(path=screenshot_path)

                content = await page.content()
                sql_error = self._check_sql_errors(content)
                if sql_error:
                    logs.append(f"SQL Error detected: {sql_error}")
                    return screenshot_path, logs, True

            except Exception as e:
                logs.append(f"Capture error: {e}")
                logger.error(f"Generic capture failed: {e}", exc_info=True)

        return screenshot_path, logs, False
    
    def _construct_payload_url(self, url: str, payload: Optional[str]) -> str:
        """Construct URL with payload injected."""
        if not payload or payload in url:
            return url
            
        import urllib.parse as urlparse
        from urllib.parse import urlencode, parse_qs
        
        parsed = urlparse.urlparse(url)
        if parsed.query:
            qs = parse_qs(parsed.query)
            for k in qs:
                qs[k] = payload
            new_query = urlencode(qs, doseq=True)
            return urlparse.urlunparse(parsed._replace(query=new_query))
        else:
            return f"{url}?q={payload}"
    
    def _detect_vuln_type(self, finding: Dict[str, Any]) -> str:
        """Detect vulnerability type from finding data."""
        title = finding.get("title", "").upper()
        vuln_type = finding.get("type", "").upper()
        
        if "XSS" in title or "XSS" in vuln_type or "CROSS-SITE" in title:
            return "xss"
        elif "SQL" in title or "SQLI" in vuln_type:
            return "sqli"
        else:
            return "general"
    
    async def _call_vision_model(self, prompt: str, screenshot_path: str) -> str:
        """
        Call a vision-capable LLM to analyze the screenshot.
        Uses OpenRouter with a vision model.
        """
        from bugtrace.core.llm_client import LLMClient
        
        llm = LLMClient()
        
        # Use a vision-capable model
        # google/gemini-2.0-flash-001 is a good default, or use settings
        response = await llm.generate_with_image(
            prompt=prompt,
            image_path=screenshot_path,
            model_override="google/gemini-2.0-flash-001",
            temperature=0.1
        )
        
        return response
    
    def _parse_vision_response(self, response: str) -> Dict[str, Any]:
        """Parse the JSON response from vision model."""
        import json
        import re
        
        try:
            # 1. Direct JSON extraction (more robust than the previous regex)
            # Find the first { and last }
            start = response.find('{')
            end = response.rfind('}')
            if start != -1 and end != -1:
                json_str = response[start:end+1]
                # Clean potential markdown ticks
                json_str = json_str.strip('`').strip()
                data = json.loads(json_str)
                # Normalize keys
                if 'success' not in data and 'validated' in data:
                    data['success'] = data['validated']
                if 'evidence' not in data and 'description' in data:
                    data['evidence'] = data['description']
                return data
        except Exception as e:
            logger.debug(f"JSON parsing failed: {e}")
            
        # 2. Fallback: Parse as text (More conservative)
        # Search for confirmation keywords but ensure they aren't negated
        positive = ["confirmed", "validated", "execution detected", "payload successful"]
        response_lower = response.lower()
        
        # If we see "success": false or "validated": false, it's a clear NO
        if '"success": false' in response_lower or '"validated": false' in response_lower:
            return {"success": False, "confidence": 1.0, "evidence": response[:500]}
            
        is_success = any(p in response_lower for p in positive)
        # Handle "success": true
        if '"success": true' in response_lower or '"validated": true' in response_lower:
            is_success = True
            
        return {
            "success": is_success,
            "confidence": 0.5 if is_success else 0.0,
            "evidence": response[:500]
        }
    
    def _batch_filter_findings(self, findings: List[Dict[str, Any]]) -> Tuple[List, List, List]:
        """Filter findings into pre-validated, skipped, and needs validation."""
        pre_validated = []
        needs_validation = []
        skipped = []

        for finding in findings:
            # Already validated
            if finding.get("validated") or finding.get("status") == "VALIDATED_CONFIRMED":
                pre_validated.append(finding)
                self._stats["skipped_prevalidated"] += 1
                continue

            # Low severity
            severity = finding.get("severity", "").upper()
            if severity in ["INFO", "SAFE", "INFORMATIONAL"]:
                skipped.append(finding)
                continue

            needs_validation.append(finding)

        return pre_validated, needs_validation, skipped

    async def _batch_validate_single(self, finding: Dict, index: int, total: int) -> Dict:
        """Wrapper for single validation with error handling."""
        try:
            dashboard.update_task(
                "AgenticValidator",
                status=f"Validating {index+1}/{total}: {finding.get('type', 'unknown')}"
            )
            return await self.validate_finding_agentically(finding)
        except Exception as e:
            logger.error(f"Validation failed for {finding.get('url', 'unknown')}: {e}", exc_info=True)
            finding["validated"] = False
            finding["reasoning"] = f"Validation error: {str(e)}"
            return finding

    def _batch_collect_results(self, done: set, validated_results: List[Any]):
        """Collect completed task results."""
        for task in done:
            idx = int(task.get_name().split("_")[1])
            try:
                validated_results[idx] = task.result()
            except Exception as e:
                validated_results[idx] = e

    def _batch_handle_pending(self, pending: set, validated_results: List[Any]):
        """Handle pending tasks on timeout."""
        logger.warning(f"Batch validation timed out. {len(pending)} tasks pending.")
        for task in pending:
            idx = int(task.get_name().split("_")[1])
            task.cancel()
            validated_results[idx] = RuntimeError("Validation Timeout")

    async def _batch_execute_parallel(self, needs_validation: List[Dict[str, Any]]) -> List[Any]:
        """Execute parallel validation with timeout handling."""
        tasks = [
            asyncio.create_task(
                self._batch_validate_single(finding, i, len(needs_validation)),
                name=f"validate_{i}"
            )
            for i, finding in enumerate(needs_validation)
        ]

        validated_results = [None] * len(needs_validation)
        try:
            done, pending = await asyncio.wait(
                tasks,
                timeout=self.MAX_TOTAL_VALIDATION_TIME,
                return_when=asyncio.ALL_COMPLETED
            )

            self._batch_collect_results(done, validated_results)

            if pending:
                self._batch_handle_pending(pending, validated_results)

        except Exception as e:
            logger.error(f"Batch validation failed: {e}", exc_info=True)
            for i, r in enumerate(validated_results):
                if r is None:
                    validated_results[i] = RuntimeError(f"Batch Error: {e}")

        return validated_results

    def _batch_process_results(
        self, validated_results: List[Any], needs_validation: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Process validation results and handle exceptions."""
        validated_findings = []
        for i, result in enumerate(validated_results):
            if result is None or isinstance(result, Exception):
                error_msg = str(result) if result else "Unknown error"
                logger.error(f"Task {i} failed: {error_msg}")
                original = needs_validation[i]
                original["validated"] = False
                original["status"] = "VALIDATION_ERROR"
                original["reasoning"] = f"Exception: {error_msg}"
                validated_findings.append(original)
            else:
                validated_findings.append(result)
        return validated_findings

    def _batch_log_stats(
        self, total: int, pre_validated: List, validated_findings: List, elapsed: float
    ):
        """Log batch validation statistics."""
        stats = self.get_stats()
        logger.info(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ AGENTIC VALIDATOR BATCH COMPLETE                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Total Findings:     {total:>5}                                   â•‘
â•‘ Pre-validated:      {len(pre_validated):>5} (fast-path)                       â•‘
â•‘ Actually Validated: {len(validated_findings):>5}                                   â•‘
â•‘ Cache Hits:         {stats['cache_hits']:>5}                                   â•‘
â•‘ CDP Confirmed:      {stats['cdp_confirmed']:>5} (skipped vision)               â•‘
â•‘ Vision Analyzed:    {stats['vision_analyzed']:>5}                                   â•‘
â•‘ Avg Time/Finding:   {stats['avg_time_ms']:.0f}ms                                â•‘
â•‘ Total Time:         {elapsed:.1f}s                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        dashboard.log(f"âœ… Batch validation complete: {elapsed:.1f}s total, {stats['avg_time_ms']:.0f}ms avg", "SUCCESS")

    async def validate_batch(self, findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        OPTIMIZED: Validate a batch of findings using parallel processing.

        Improvements over v1:
        - Parallel validation (up to MAX_CONCURRENT_VALIDATIONS simultaneous)
        - Smart filtering (skip pre-validated, low-severity)
        - No fixed sleep delays
        - Progress tracking via dashboard
        """
        start_time = time.time()
        total = len(findings)
        self.think(f"ðŸš€ Starting PARALLEL validation for {total} findings (concurrency={self.MAX_CONCURRENT_VALIDATIONS})")

        # Phase 1: Smart filtering
        pre_validated, needs_validation, skipped = self._batch_filter_findings(findings)

        logger.info(f"Batch breakdown: {len(pre_validated)} pre-validated, {len(skipped)} skipped, {len(needs_validation)} to validate")
        dashboard.log(f"âš¡ Fast-path: {len(pre_validated)} already validated, {len(needs_validation)} queued for audit", "INFO")

        # Check for cancellation
        if self._cancellation_token.get("cancelled", False):
            logger.info("Batch validation cancelled by user")
            return pre_validated + skipped

        # Phase 2: Parallel validation
        validated_results = await self._batch_execute_parallel(needs_validation)

        # Phase 3: Process results
        validated_findings = self._batch_process_results(validated_results, needs_validation)

        # Phase 4: Combine and log
        all_results = pre_validated + skipped + validated_findings
        elapsed = time.time() - start_time
        self._batch_log_stats(total, pre_validated, validated_findings, elapsed)

        return all_results

    async def validate_batch_parallel(
        self,
        findings: List[Dict[str, Any]],
        max_concurrent: int = None
    ) -> List[Dict[str, Any]]:
        """
        Alternative batch validation with custom concurrency.
        Use this for finer control over parallelism.
        """
        if max_concurrent:
            original = self.MAX_CONCURRENT_VALIDATIONS
            self.MAX_CONCURRENT_VALIDATIONS = max_concurrent
            self._validation_semaphore = asyncio.Semaphore(max_concurrent)
            try:
                return await self.validate_batch(findings)
            finally:
                self.MAX_CONCURRENT_VALIDATIONS = original
                self._validation_semaphore = asyncio.Semaphore(original)
        else:
            return await self.validate_batch(findings)

    def clear_cache(self):
        """Clear the validation cache."""
        self._cache.clear()
        logger.info("Validation cache cleared")

    def reset_stats(self):
        """Reset validation statistics."""
        self._stats = {
            "total_validated": 0,
            "cache_hits": 0,
            "cdp_confirmed": 0,
            "vision_analyzed": 0,
            "skipped_prevalidated": 0,
            "avg_time_ms": 0,
            "total_time_ms": 0
        }

    # =========================================================================
    # NOTE: Feedback loop methods removed for simplicity
    # AgenticValidator is now a linear CDP specialist - no loopback to
    # XSSAgent/CSTIAgent for variant generation.
    #
    # Removed methods:
    # - _generate_feedback()
    # - _request_payload_variant()
    # - _get_xss_variant()
    # - _get_csti_variant()
    #
    # Filtering now happens at ValidationEngine level based on status field.
    # =========================================================================


# Singleton instance for convenience
agentic_validator = AgenticValidator()
