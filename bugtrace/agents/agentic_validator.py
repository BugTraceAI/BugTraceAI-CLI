"""
AgenticValidator: AI-Powered Vulnerability Validation Agent (v2 - OPTIMIZED)

PERFORMANCE OPTIMIZATIONS (2026-01-21):
1. Parallel validation with configurable concurrency (3x-5x faster)
2. Browser session pooling (reuse instead of launch per validation)
3. Early-exit when CDP confirms (skip expensive vision API)
4. Result caching for similar payloads/URLs (avoid re-validation)
5. Smart fast-path for high-confidence/pre-validated findings
6. Reduced timeouts and eliminated unnecessary sleeps
7. Batch screenshot capture for similar URLs

This validator uses an LLM with vision capabilities to:
1. Navigate to target URLs with payloads
2. Capture screenshots
3. Reason about the visual state to determine if vulnerability is real
4. Adapt testing strategy based on context
"""

from typing import List, Dict, Any, Tuple, Optional, Set
import asyncio
import base64
import json
import hashlib
import time
from pathlib import Path
from loguru import logger
from dataclasses import dataclass, field
from collections import OrderedDict

from bugtrace.agents.base import BaseAgent
from bugtrace.tools.visual.browser import browser_manager, BrowserManager
from bugtrace.tools.visual.verifier import XSSVerifier, VerificationResult
from bugtrace.core.ui import dashboard
from bugtrace.core.config import settings
from bugtrace.core.llm_client import llm_client
# NOTE: ValidationFeedback imports removed - feedback loop eliminated for simplicity
# AgenticValidator is now a linear CDP specialist (no loopback to specialist agents)


# =============================================================================
# OPTIMIZATION 1: Validation Result Cache (LRU)
# =============================================================================
@dataclass
class ValidationCache:
    """LRU Cache for validation results to avoid re-validating identical payloads."""
    max_size: int = 100
    _cache: OrderedDict = field(default_factory=OrderedDict)

    def get_key(self, url: str, payload: str) -> str:
        """Generate cache key from full URL + payload hash.

        NOTE: We include the full URL (with query params) because different
        parameter values may have different escaping/filtering behavior.
        E.g., /user?id=1 vs /user?id=100 might have different XSS contexts.
        """
        from urllib.parse import urlparse, parse_qs, urlencode
        parsed = urlparse(url)
        # Sort query params for consistent caching
        params = parse_qs(parsed.query, keep_blank_values=True)
        sorted_query = urlencode(sorted(params.items()), doseq=True) if params else ""
        normalized_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{sorted_query}" if sorted_query else f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
        content = f"{normalized_url}:{payload or 'none'}"
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, url: str, payload: str) -> Optional[Dict]:
        """Get cached result if exists."""
        key = self.get_key(url, payload)
        if key in self._cache:
            self._cache.move_to_end(key)  # LRU: move to end
            logger.debug(f"Cache HIT for {url[:50]}...")
            return self._cache[key]
        return None

    def set(self, url: str, payload: str, result: Dict):
        """Cache a validation result."""
        key = self.get_key(url, payload)
        self._cache[key] = result
        self._cache.move_to_end(key)
        # Evict oldest if over capacity
        while len(self._cache) > self.max_size:
            self._cache.popitem(last=False)

    def clear(self):
        self._cache.clear()

    def __len__(self):
        return len(self._cache)


# =============================================================================
# OPTIMIZATION 2: Shared XSSVerifier Pool
# =============================================================================
class VerifierPool:
    """Pool of XSSVerifier instances to avoid recreation overhead."""

    def __init__(self, pool_size: int = 3):
        self.pool_size = pool_size
        self._verifiers: List[XSSVerifier] = []
        self._semaphore: Optional[asyncio.Semaphore] = None
        self._initialized = False

    async def initialize(self):
        """Initialize verifier pool (lazy init)."""
        if self._initialized:
            return
        self._semaphore = asyncio.Semaphore(self.pool_size)
        self._verifiers = [
            XSSVerifier(headless=settings.HEADLESS_BROWSER, prefer_cdp=False)
            for _ in range(self.pool_size)
        ]
        self._initialized = True
        logger.info(f"VerifierPool initialized with {self.pool_size} instances")

    async def get_verifier(self) -> XSSVerifier:
        """Get an available verifier from the pool."""
        if not self._initialized:
            await self.initialize()
        await self._semaphore.acquire()
        # Return any verifier (they're stateless between calls)
        return self._verifiers[0]

    def release(self):
        """Release verifier back to pool."""
        if self._semaphore:
            self._semaphore.release()


# Global pool instance
_verifier_pool = VerifierPool(pool_size=3)


class AgenticValidator(BaseAgent):
    """
    An AI-powered validator that uses vision + reasoning to validate vulnerabilities.

    v2 OPTIMIZATIONS:
    - Parallel batch validation (configurable concurrency)
    - Result caching for identical URL+payload combinations
    - Early-exit when CDP confirms (skips expensive vision API)
    - Browser session reuse via VerifierPool
    - Smart filtering of pre-validated and low-severity findings

    Unlike the basic ValidatorAgent which just checks for alert(), this agent:
    - Takes screenshots and sends them to a vision LLM
    - Asks the LLM to reason about what it sees
    - Can adapt its testing strategy based on the response
    - Provides detailed evidence with confidence scores
    """

    # Configuration
    MAX_CONCURRENT_VALIDATIONS = 3  # Parallel browser sessions
    SKIP_VISION_ON_CDP_CONFIRM = True  # Early exit optimization
    ENABLE_CACHE = True  # Result caching
    FAST_VALIDATION_TIMEOUT = 30.0  # Reduced from default
    MAX_TOTAL_VALIDATION_TIME = 600.0  # 10 minutes global timeout (was 300s - too aggressive)
    MAX_FEEDBACK_DEPTH = 2  # Maximum recursion depth for feedback loop

    def __init__(self, event_bus=None, cancellation_token=None):
        super().__init__("AgenticValidator", "AI Vision Validator", event_bus, agent_id="agentic_validator")
        self.max_retries = 3
        self.validation_prompts = self._load_prompts()
        
        # Cancellation token for graceful shutdown (injected from orchestrator)
        self._cancellation_token = cancellation_token or {"cancelled": False}

        # OPTIMIZATION: Validation cache
        self._cache = ValidationCache(max_size=150)

        # OPTIMIZATION: Concurrency semaphore for parallel validation
        self._validation_semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_VALIDATIONS)

        # Statistics tracking
        self._stats = {
            "total_validated": 0,
            "cache_hits": 0,
            "cdp_confirmed": 0,
            "vision_analyzed": 0,
            "skipped_prevalidated": 0,
            "avg_time_ms": 0,
            "total_time_ms": 0
        }

        # NOTE: Feedback loop removed - AgenticValidator is now a linear CDP specialist
        # No loopback to XSSAgent/CSTIAgent - validation is single-attempt
        self.llm_client = llm_client
        
    def _load_prompts(self) -> Dict[str, str]:
        """Load specialized prompts for different vulnerability types from external config."""
        prompts = {
            "xss": """You are a security expert analyzing a screenshot for XSS vulnerability validation.

CONTEXT:
- BugTraceAI security scanner found a potential XSS vulnerability
- We injected a test payload that creates a visual banner or triggers an alert
- Our payloads create text containing: "HACKED BY BUGTRACEAI", "FRAGMENT XSS", "MXSS DETECTED", or trigger alert dialogs

TASK:
Look at this screenshot and determine if the XSS was successful.

SUCCESS indicators (HIGH CONFIDENCE - mark success=true):
1. ANY text containing "HACKED", "BUGTRACEAI", "BUGTRACE", "PWNED", "XSS" appearing on the page (banner, div, any element)
2. A browser alert/confirm/prompt dialog box (usually a small popup with OK button)
3. Red or colored banner at top/bottom of page with security-related text
4. Text like "FRAGMENT XSS" or "MXSS DETECTED" visible anywhere

MEDIUM CONFIDENCE indicators (mark success=true, confidence=0.7):
1. Unusual HTML elements that look injected (e.g., floating divs, unexpected banners)
2. JavaScript code visible as rendered content (not escaped)
3. Page layout disruption suggesting DOM manipulation

FAILURE indicators (mark success=false):
1. Normal page content with no abnormalities
2. Error message like "Invalid input" or "Not found"
3. The payload is visible as escaped text (e.g., "&lt;script&gt;" shown literally)
4. WAF/security block page ("Request blocked", "Forbidden")

IMPORTANT: If you see ANY text containing "HACKED" or "BUGTRACEAI" or "XSS" that wasn't part of the original page content, this is SUCCESS - our payload executed.

Respond in JSON format:
{
    "success": true/false,
    "confidence": 0.0-1.0,
    "evidence": "description of what you see that proves/disproves XSS",
    "recommendation": "next steps if any"
}""",
            
            "sqli": """You are a security expert analyzing a screenshot for SQL Injection validation.

CONTEXT:
- A security scanner found a potential SQL Injection vulnerability
- We injected a test payload into the page
- Look for signs of SQL error messages or data exfiltration

SUCCESS indicators:
1. SQL error messages (MySQL, PostgreSQL, MSSQL syntax errors)
2. Database version disclosure
3. Unexpected data being displayed
4. "You have an error in your SQL syntax" message
5. Column/table names visible in error

FAILURE indicators:
1. Normal page with expected content
2. Generic "Invalid input" error (input validation, not SQLi)
3. WAF block page
4. HTTP 500 with no SQL-related info

Respond in JSON format:
{
    "success": true/false,
    "confidence": 0.0-1.0,
    "evidence": "description of what you see",
    "sql_error_type": "MySQL/PostgreSQL/MSSQL/None",
    "recommendation": "next steps"
}""",

            "general": """You are a security expert analyzing a screenshot for vulnerability validation.

Examine the screenshot and determine if there are any signs of:
1. Security vulnerability exploitation
2. Error messages revealing sensitive information
3. Unexpected behavior that indicates a vulnerability
4. WAF/security tool blocking

Respond in JSON format:
{
    "anomaly_detected": true/false,
    "confidence": 0.0-1.0,
    "description": "what you observe",
    "security_implications": "potential impact if any"
}"""
        }
        
        if self.system_prompt:
             # Try to split by header if they exist (Handle both H1 and H2)
             import re
             parts = re.split(r'#+\s+', self.system_prompt)
             for part in parts:
                 if part.lower().startswith("xss validation prompt"):
                     prompts["xss"] = re.sub(r'^xss validation prompt\s*', '', part, flags=re.IGNORECASE).strip()
                 elif part.lower().startswith("sqli validation prompt"):
                     prompts["sqli"] = re.sub(r'^sqli validation prompt\s*', '', part, flags=re.IGNORECASE).strip()
                 elif part.lower().startswith("general validation prompt"):
                     prompts["general"] = re.sub(r'^general validation prompt\s*', '', part, flags=re.IGNORECASE).strip()
                         
        return prompts
    
    async def run_loop(self):
        """Typically triggered by orchestrator, not continuous."""
        pass
    
    async def validate_with_vision(
        self, 
        finding: Dict[str, Any],
        screenshot_path: str
    ) -> Dict[str, Any]:
        """
        Use a vision LLM to analyze the screenshot and validate the finding.
        """
        vuln_type = self._detect_vuln_type(finding)
        prompt = self.validation_prompts.get(vuln_type, self.validation_prompts["general"])
        
        try:
            # Call vision model
            response = await self._call_vision_model(prompt, screenshot_path)
            result = self._parse_vision_response(response)
            
            finding["validated"] = result.get("success", False)
            finding["confidence"] = result.get("confidence", 0.0)
            finding["reasoning"] = result.get("evidence", "No clear evidence found in screenshot.")
            finding["validator_notes"] = response # Store full LLM reasoning
            
            if finding["validated"]:
                self.think(f"âœ… CONFIRMED: {finding.get('url')} (confidence: {result.get('confidence')})")
            else:
                self.think(f"âŒ Could not confirm via vision: {finding.get('url')}")
                
        except Exception as e:
            logger.error(f"Vision validation failed: {e}")
            finding["validated"] = False
            finding["reasoning"] = f"Vision validation error: {str(e)}"
            
        return finding
    
    async def validate_finding_agentically(
        self,
        finding: Dict[str, Any],
        _recursion_depth: int = 0
    ) -> Dict[str, Any]:
        """
        V3 Reproduction Flow (Auditor Role) - OPTIMIZED:
        1. Check cache for previous result
        2. Construct exploitation URL
        3. Navigate with CDP-enabled session (pooled)
        4. Listen for low-level execution events
        5. EARLY EXIT if CDP confirms (skip vision)
        6. Analyze with Vision only if events are silent
        7. Cache result for future use
        """
        # Check for cancellation
        if self._cancellation_token.get("cancelled", False):
            return {"validated": False, "reasoning": "Validation cancelled by user"}
        
        # Prevent infinite recursion
        if _recursion_depth >= self.MAX_FEEDBACK_DEPTH:
            logger.warning(f"Max feedback depth ({self.MAX_FEEDBACK_DEPTH}) reached, stopping recursion")
            return {"validated": False, "reasoning": "Max feedback retries exceeded"}
        
        start_time = time.time()
        url = finding.get("url")
        payload = finding.get("payload")
        vuln_type = self._detect_vuln_type(finding)
        
        # Select best verification URL from specialist methods if available
        if finding.get("verification_methods"):
            # Prefer console_log or window_variable method (more reliable than alert)
            preferred = ["console_log", "window_variable", "dom_modification"]
            found_better = False
            for p_type in preferred:
                 for m in finding.get("verification_methods", []):
                     if m.get("type") == p_type and m.get("url_encoded"):
                         url = m.get("url_encoded")
                         payload = None # URL already has payload
                         logger.info(f"Using specialized verification method: {p_type}")
                         found_better = True
                         break
                 if found_better: break

        if not url:
            return {"validated": False, "reasoning": "Missing target URL"}

        # =====================================================================
        # OPTIMIZATION: Check cache first
        # =====================================================================
        if self.ENABLE_CACHE:
            cached = self._cache.get(url, payload)
            if cached:
                self._stats["cache_hits"] += 1
                logger.info(f"ðŸš€ Cache hit for {url[:50]}... (skipping validation)")
                return cached

        self.think(f"Auditing {vuln_type} on {url}")

        # =====================================================================
        # OPTIMIZATION: Use semaphore for controlled concurrency
        # =====================================================================
        async with self._validation_semaphore:
            # Step 1: Execute in browser with timeout
            try:
                screenshot_path, logs, basic_triggered = await asyncio.wait_for(
                    self._execute_payload_optimized(url, payload, vuln_type),
                    timeout=self.FAST_VALIDATION_TIMEOUT
                )
            except asyncio.TimeoutError:
                logger.warning(f"Validation timeout for {url[:50]}...")
                return {
                    "validated": False,
                    "reasoning": f"Validation timed out after {self.FAST_VALIDATION_TIMEOUT}s",
                    "screenshot_path": None,
                    "logs": ["TIMEOUT"]
                }

            result = {
                "validated": False,
                "status": "VALIDATED_FALSE_POSITIVE",  # Default, will be updated if confirmed
                "reasoning": "",
                "screenshot_path": screenshot_path,
                "logs": logs
            }

            # =================================================================
            # OPTIMIZATION: Early exit on CDP confirmation (skip vision API)
            # =================================================================
            if basic_triggered:
                self._stats["cdp_confirmed"] += 1
                result["validated"] = True
                result["status"] = "VALIDATED_CONFIRMED"
                result["reasoning"] = f"Execution CONFIRMED: Low-level event (alert/dialog) triggered. Logs: {logs}"

                # Cache successful result
                if self.ENABLE_CACHE:
                    self._cache.set(url, payload, result)

                elapsed = (time.time() - start_time) * 1000
                self._update_stats(elapsed)
                logger.info(f"âš¡ CDP confirmed in {elapsed:.0f}ms (skipped vision API)")
                return result

            # =================================================================
            # Step 3: Visual/Vision Analysis (only if CDP silent)
            # =================================================================
            if screenshot_path and Path(screenshot_path).exists():
                self.think("CDP silent. Invoking Vision Analysis...")
                self._stats["vision_analyzed"] += 1

                vision_result = await self.validate_with_vision(finding, screenshot_path)

                confidence = vision_result.get("confidence", 0.0)
                validated = vision_result.get("validated", False)

                if validated:
                    result["validated"] = True
                    result["status"] = "VALIDATED_CONFIRMED"
                    result["reasoning"] = vision_result.get("reasoning", "Validated via vision analysis.")
                elif confidence >= 0.7:
                    result["validated"] = False
                    result["status"] = "MANUAL_REVIEW_RECOMMENDED"
                    result["needs_manual_review"] = True
                    result["reasoning"] = self._generate_manual_review_brief(finding, vision_result, logs)
                    self.think(f"âš ï¸ SUSPICIOUS ({confidence:.0%}) - flagging for manual review")
                else:
                    result["validated"] = False
                    result["status"] = "VALIDATED_FALSE_POSITIVE"
                    result["reasoning"] = vision_result.get("reasoning", "No evidence of execution found.")
            else:
                result["reasoning"] = "Audit failed: Could not capture screenshot."

            # Cache result (both positive and negative)
            if self.ENABLE_CACHE:
                self._cache.set(url, payload, result)

            # NOTE: Feedback loop removed - AgenticValidator is now linear CDP-only
            # No recursion to specialist agents. Single-attempt validation.

            elapsed = (time.time() - start_time) * 1000
            self._update_stats(elapsed)

            return result

    def _update_stats(self, elapsed_ms: float):
        """Update validation statistics."""
        self._stats["total_validated"] += 1
        self._stats["total_time_ms"] += elapsed_ms
        self._stats["avg_time_ms"] = self._stats["total_time_ms"] / self._stats["total_validated"]

    def get_stats(self) -> Dict[str, Any]:
        """Get validation statistics for reporting."""
        return {
            **self._stats,
            "cache_size": len(self._cache)
        }

    async def _execute_payload_optimized(
        self,
        url: str,
        payload: Optional[str],
        vuln_type: str
    ) -> Tuple[str, List[str], bool]:
        """
        OPTIMIZED payload execution using pooled verifiers.
        """
        if vuln_type == "xss":
            # Use pooled verifier instead of creating new one each time
            verifier = await _verifier_pool.get_verifier()
            try:
                target_url = self._construct_payload_url(url, payload)
                result = await verifier.verify_xss(
                    target_url,
                    screenshot_dir=str(settings.LOG_DIR),
                    timeout=self.FAST_VALIDATION_TIMEOUT - 5  # Leave margin
                )
                return result.screenshot_path, result.console_logs or [], result.success
            finally:
                _verifier_pool.release()
        else:
            return await self._generic_capture(url, payload)

    # NOTE: _has_specialist_authority removed - filtering now happens at ValidationEngine level

    def _generate_manual_review_brief(self, finding: Dict, vision_result: Dict, browser_logs: List) -> str:
        """Constructs a detailed explanation for manual triagers."""
        url = finding.get("url", "N/A")
        param = finding.get("parameter", "N/A")
        payload = finding.get("payload", "N/A")
        vision_evidence = vision_result.get("evidence", "No evidence provided by vision model.")
        confidence = vision_result.get("confidence", 0.0)
        
        brief = [
            "### ðŸ”Ž DETAILED MANUAL REVIEW BRIEF",
            f"**Target:** {url}",
            f"**Parameter:** `{param}`",
            f"**Payload:** `{payload}`",
            "",
            "#### ðŸ•µï¸ HUNTER OBSERVATIONS",
            "- Reflection detected in raw HTML (possible decoded or mutated form).",
            "- WAF presence suspected or bypass attempts initiated.",
            "",
            "#### ðŸ¤– AUDITOR (AGENTIC) AUDIT",
            f"- **Vision Confidence:** {confidence:.0%}",
            f"- **Execution Events (CDP):** {'None' if not browser_logs else f'Detected {len(browser_logs)} events'}",
            f"- **Vision Analysis:** {vision_evidence}",
            "",
            "#### ðŸ› ï¸ WHAT TO LOOK FOR (MANUAL CHECK)",
            "1. Open the target URL with the payload.",
            "2. Check if a **RED BANNER** with text **'HACKED BY BUGTRACEAI'** appears at the top.",
            "3. Check the Browser Console for successful `fetch` requests or execution logs.",
            "",
            "#### â“ WHY MANUAL REVIEW?",
            "Automatic validation is inconclusive because " + 
            ("the Vision AI detected a potential anomaly but no low-level protocol event (like an alert) was captured." if confidence >= 0.7 
             else "there is a strong indicator of vulnerability (reflection) but visual proof is obscured or non-standard.")
        ]
        return "\n".join(brief)
    
    async def _execute_payload(
        self, 
        url: str, 
        payload: Optional[str],
        vuln_type: str
    ) -> Tuple[str, List[str], bool]:
        """
        Execute the payload in browser and capture result.
        Returns (screenshot_path, logs, basic_triggered)
        """
        if vuln_type == "xss":
            # Use Playwright for current environment stability
            verifier = XSSVerifier(headless=settings.HEADLESS_BROWSER, prefer_cdp=False)
            target_url = self._construct_payload_url(url, payload)
            
            result = await verifier.verify_xss(target_url, screenshot_dir=str(settings.LOG_DIR))
            return result.screenshot_path, result.console_logs, result.success
        else:
            # Generic page capture for other types
            return await self._generic_capture(url, payload)
    
    async def _generic_capture(
        self, 
        url: str, 
        payload: Optional[str]
    ) -> Tuple[str, List[str], bool]:
        """
        Generic page capture for non-XSS validations.
        """
        logs = []
        screenshot_path = ""
        
        target_url = self._construct_payload_url(url, payload) if payload else url
        
        async with browser_manager.get_page() as page:
            try:
                await page.goto(target_url, wait_until="domcontentloaded", timeout=30000)
                await page.wait_for_timeout(2000)
                
                import uuid
                screenshot_path = str(settings.LOG_DIR / f"validate_{uuid.uuid4().hex[:8]}.png")
                await page.screenshot(path=screenshot_path)
                
                # Check page content for error indicators
                content = await page.content()
                
                # SQL error patterns
                sql_errors = [
                    "SQL syntax",
                    "mysql_",
                    "ORA-",
                    "PostgreSQL",
                    "SQLITE_ERROR",
                    "Microsoft SQL Server"
                ]
                
                for error in sql_errors:
                    if error.lower() in content.lower():
                        logs.append(f"SQL Error detected: {error}")
                        return screenshot_path, logs, True
                        
            except Exception as e:
                logs.append(f"Capture error: {e}")
                logger.error(f"Generic capture failed: {e}")
                
        return screenshot_path, logs, False
    
    def _construct_payload_url(self, url: str, payload: Optional[str]) -> str:
        """Construct URL with payload injected."""
        if not payload or payload in url:
            return url
            
        import urllib.parse as urlparse
        from urllib.parse import urlencode, parse_qs
        
        parsed = urlparse.urlparse(url)
        if parsed.query:
            qs = parse_qs(parsed.query)
            for k in qs:
                qs[k] = payload
            new_query = urlencode(qs, doseq=True)
            return urlparse.urlunparse(parsed._replace(query=new_query))
        else:
            return f"{url}?q={payload}"
    
    def _detect_vuln_type(self, finding: Dict[str, Any]) -> str:
        """Detect vulnerability type from finding data."""
        title = finding.get("title", "").upper()
        vuln_type = finding.get("type", "").upper()
        
        if "XSS" in title or "XSS" in vuln_type or "CROSS-SITE" in title:
            return "xss"
        elif "SQL" in title or "SQLI" in vuln_type:
            return "sqli"
        else:
            return "general"
    
    async def _call_vision_model(self, prompt: str, screenshot_path: str) -> str:
        """
        Call a vision-capable LLM to analyze the screenshot.
        Uses OpenRouter with a vision model.
        """
        from bugtrace.core.llm_client import LLMClient
        
        llm = LLMClient()
        
        # Use a vision-capable model
        # google/gemini-2.0-flash-001 is a good default, or use settings
        response = await llm.generate_with_image(
            prompt=prompt,
            image_path=screenshot_path,
            model_override="google/gemini-2.0-flash-001",
            temperature=0.1
        )
        
        return response
    
    def _parse_vision_response(self, response: str) -> Dict[str, Any]:
        """Parse the JSON response from vision model."""
        import json
        import re
        
        try:
            # 1. Direct JSON extraction (more robust than the previous regex)
            # Find the first { and last }
            start = response.find('{')
            end = response.rfind('}')
            if start != -1 and end != -1:
                json_str = response[start:end+1]
                # Clean potential markdown ticks
                json_str = json_str.strip('`').strip()
                data = json.loads(json_str)
                # Normalize keys
                if 'success' not in data and 'validated' in data:
                    data['success'] = data['validated']
                if 'evidence' not in data and 'description' in data:
                    data['evidence'] = data['description']
                return data
        except Exception as e:
            logger.debug(f"JSON parsing failed: {e}")
            
        # 2. Fallback: Parse as text (More conservative)
        # Search for confirmation keywords but ensure they aren't negated
        positive = ["confirmed", "validated", "execution detected", "payload successful"]
        response_lower = response.lower()
        
        # If we see "success": false or "validated": false, it's a clear NO
        if '"success": false' in response_lower or '"validated": false' in response_lower:
            return {"success": False, "confidence": 1.0, "evidence": response[:500]}
            
        is_success = any(p in response_lower for p in positive)
        # Handle "success": true
        if '"success": true' in response_lower or '"validated": true' in response_lower:
            is_success = True
            
        return {
            "success": is_success,
            "confidence": 0.5 if is_success else 0.0,
            "evidence": response[:500]
        }
    
    async def validate_batch(self, findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        OPTIMIZED: Validate a batch of findings using parallel processing.

        Improvements over v1:
        - Parallel validation (up to MAX_CONCURRENT_VALIDATIONS simultaneous)
        - Smart filtering (skip pre-validated, low-severity)
        - No fixed sleep delays
        - Progress tracking via dashboard
        """
        start_time = time.time()
        total = len(findings)
        self.think(f"ðŸš€ Starting PARALLEL validation for {total} findings (concurrency={self.MAX_CONCURRENT_VALIDATIONS})")

        # =====================================================================
        # PHASE 1: Smart filtering - separate what needs validation
        # =====================================================================
        pre_validated = []
        needs_validation = []
        skipped = []

        for finding in findings:
            # Already validated by specialist agent (defensive check)
            # NOTE: ValidationEngine should filter these, but double-check here
            if finding.get("validated") or finding.get("status") == "VALIDATED_CONFIRMED":
                pre_validated.append(finding)
                self._stats["skipped_prevalidated"] += 1
                continue

            # Low severity - skip validation
            severity = finding.get("severity", "").upper()
            if severity in ["INFO", "SAFE", "INFORMATIONAL"]:
                skipped.append(finding)
                continue

            # All remaining findings need CDP validation
            # NOTE: Filtering by vuln type now happens at ValidationEngine level
            needs_validation.append(finding)

        logger.info(f"Batch breakdown: {len(pre_validated)} pre-validated, {len(skipped)} skipped, {len(needs_validation)} to validate")
        dashboard.log(f"âš¡ Fast-path: {len(pre_validated)} already validated, {len(needs_validation)} queued for audit", "INFO")

        # =====================================================================
        # PHASE 2: Parallel validation of remaining findings
        # =====================================================================
        async def validate_single(finding: Dict, index: int) -> Dict:
            """Wrapper for single validation with error handling."""
            try:
                dashboard.update_task(
                    "AgenticValidator",
                    status=f"Validating {index+1}/{len(needs_validation)}: {finding.get('type', 'unknown')}"
                )
                return await self.validate_finding_agentically(finding)
            except Exception as e:
                logger.error(f"Validation failed for {finding.get('url', 'unknown')}: {e}")
                finding["validated"] = False
                finding["reasoning"] = f"Validation error: {str(e)}"
                return finding

        # Check for cancellation before starting batch
        if self._cancellation_token.get("cancelled", False):
            logger.info("Batch validation cancelled by user")
            return pre_validated + skipped
        
        # Create validation tasks with index tracking for partial result handling
        tasks = [
            asyncio.create_task(validate_single(finding, i), name=f"validate_{i}")
            for i, finding in enumerate(needs_validation)
        ]

        # Execute with timeout but PRESERVE PARTIAL RESULTS
        # Using asyncio.wait instead of gather to get completed tasks on timeout
        validated_results = [None] * len(needs_validation)
        try:
            done, pending = await asyncio.wait(
                tasks,
                timeout=self.MAX_TOTAL_VALIDATION_TIME,
                return_when=asyncio.ALL_COMPLETED
            )

            # Collect completed results
            for task in done:
                # Extract index from task name
                idx = int(task.get_name().split("_")[1])
                try:
                    validated_results[idx] = task.result()
                except Exception as e:
                    validated_results[idx] = e

            # Mark pending tasks as timeout (don't lose them!)
            if pending:
                logger.warning(f"Batch validation timed out. {len(done)} completed, {len(pending)} timed out.")
                for task in pending:
                    idx = int(task.get_name().split("_")[1])
                    task.cancel()
                    validated_results[idx] = RuntimeError("Validation Timeout")

        except Exception as e:
            logger.error(f"Batch validation failed: {e}")
            # Fill remaining with errors
            for i, r in enumerate(validated_results):
                if r is None:
                    validated_results[i] = RuntimeError(f"Batch Error: {e}")

        # Process results, handling any exceptions
        validated_findings = []
        for i, result in enumerate(validated_results):
            if result is None or isinstance(result, Exception):
                error_msg = str(result) if result else "Unknown error"
                logger.error(f"Task {i} failed: {error_msg}")
                original = needs_validation[i]
                original["validated"] = False
                original["status"] = "VALIDATION_ERROR"
                original["reasoning"] = f"Exception: {error_msg}"
                validated_findings.append(original)
            else:
                validated_findings.append(result)

        # =====================================================================
        # PHASE 3: Combine all results
        # =====================================================================
        all_results = pre_validated + skipped + validated_findings

        # Log statistics
        elapsed = time.time() - start_time
        stats = self.get_stats()
        logger.info(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ AGENTIC VALIDATOR BATCH COMPLETE                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Total Findings:     {total:>5}                                   â•‘
â•‘ Pre-validated:      {len(pre_validated):>5} (fast-path)                       â•‘
â•‘ Actually Validated: {len(validated_findings):>5}                                   â•‘
â•‘ Cache Hits:         {stats['cache_hits']:>5}                                   â•‘
â•‘ CDP Confirmed:      {stats['cdp_confirmed']:>5} (skipped vision)               â•‘
â•‘ Vision Analyzed:    {stats['vision_analyzed']:>5}                                   â•‘
â•‘ Avg Time/Finding:   {stats['avg_time_ms']:.0f}ms                                â•‘
â•‘ Total Time:         {elapsed:.1f}s                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        dashboard.log(f"âœ… Batch validation complete: {elapsed:.1f}s total, {stats['avg_time_ms']:.0f}ms avg", "SUCCESS")

        return all_results

    async def validate_batch_parallel(
        self,
        findings: List[Dict[str, Any]],
        max_concurrent: int = None
    ) -> List[Dict[str, Any]]:
        """
        Alternative batch validation with custom concurrency.
        Use this for finer control over parallelism.
        """
        if max_concurrent:
            original = self.MAX_CONCURRENT_VALIDATIONS
            self.MAX_CONCURRENT_VALIDATIONS = max_concurrent
            self._validation_semaphore = asyncio.Semaphore(max_concurrent)
            try:
                return await self.validate_batch(findings)
            finally:
                self.MAX_CONCURRENT_VALIDATIONS = original
                self._validation_semaphore = asyncio.Semaphore(original)
        else:
            return await self.validate_batch(findings)

    def clear_cache(self):
        """Clear the validation cache."""
        self._cache.clear()
        logger.info("Validation cache cleared")

    def reset_stats(self):
        """Reset validation statistics."""
        self._stats = {
            "total_validated": 0,
            "cache_hits": 0,
            "cdp_confirmed": 0,
            "vision_analyzed": 0,
            "skipped_prevalidated": 0,
            "avg_time_ms": 0,
            "total_time_ms": 0
        }

    # =========================================================================
    # NOTE: Feedback loop methods removed for simplicity
    # AgenticValidator is now a linear CDP specialist - no loopback to
    # XSSAgent/CSTIAgent for variant generation.
    #
    # Removed methods:
    # - _generate_feedback()
    # - _request_payload_variant()
    # - _get_xss_variant()
    # - _get_csti_variant()
    #
    # Filtering now happens at ValidationEngine level based on status field.
    # =========================================================================


# Singleton instance for convenience
agentic_validator = AgenticValidator()
