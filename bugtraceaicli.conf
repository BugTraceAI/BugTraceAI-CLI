# ==============================================================================
# BUGTRACE AI CLI - CONFIGURATION FILE (bugtraceaicli.conf)
# ==============================================================================
# This file contains the operational settings for the autonomous framework.
# Sensitive API Keys should remain in the .env file for security.

[CORE]
# Debug mode enables verbose terminal output and detailed error tracking.
# Set to True only for troubleshooting.
DEBUG = True

# Safe Mode prevents the execution of active payload injection and exploits.
# When True, the system only simulates attacks.
SAFE_MODE = False

[LLM_MODELS]
# Orchestration and strategy. Few calls, needs reliability.
DEFAULT_MODEL = qwen/qwen3-coder

# Code analysis, payload generation, bypass logic.
CODE_MODEL = qwen/qwen3-coder

# DASTySAST analysis (high-volume: 1 call per URL). Must be FAST.
# Latency test: qwen3-coder TTFT=0.84s, Total=2.51s (fastest, clean XML)
ANALYSIS_MODEL = qwen/qwen3-coder

# Fallback chain. Both tested: clean XML output, no markdown wrapping.
PRIMARY_MODELS = qwen/qwen3-coder,x-ai/grok-4-fast

# Vision-Language Model for screenshot and UI analysis.
VISION_MODEL = google/gemini-3-flash-preview

# WAF signature detection. Few calls.
WAF_DETECTION_MODELS = qwen/qwen3-coder,x-ai/grok-4-fast

# Payload mutation and WAF bypass.
MUTATION_MODEL = x-ai/grok-4-fast

# Per-finding skeptical review. High volume, must be fast.
SKEPTICAL_MODEL = qwen/qwen3-coder

# Minimum credits in USD required in OpenRouter to run the engagement.
# The system will warn you if your balance is below this amount.
MIN_CREDITS = 2.0

# =============================================================================
# LLM CONCURRENCY MODEL (v3.1 Architecture)
# =============================================================================
# Each agent (XSS, SQLi, SSRF, etc.) makes LLM calls INDEPENDENTLY.
# There is NO global semaphore blocking agents from calling the LLM.
#
# Flow per agent:
#   [request] --> [wait for response] --> [process] --> [next request]
#
# Agents don't saturate the API because:
#   1. Each agent waits for response before sending another request
#   2. Phase semaphores limit how many agents run in parallel
#   3. tenacity retry handles 429 errors with exponential backoff
#   4. Model shifting switches to fallback model if one is rate-limited
#
# This design maximizes throughput while respecting natural rate limits.
# NO MAX_CONCURRENT_REQUESTS setting needed - removed in v3.1.
# =============================================================================

# =============================================================================
# SKEPTICAL REVIEW THRESHOLDS
# =============================================================================
# Minimum confidence score (0-10) for findings to pass to specialist agents
# Lower = more permissive (more tested), Higher = stricter (fewer tested)
# CRITICAL vulns have LOWER thresholds to avoid missing them

[SKEPTICAL_THRESHOLDS]
# CRITICAL - Moderate threshold to reduce LLM false positives
# 2026-01-23: SQL raised from 4 to 6 - LLM hypotheses were causing FPs
# A score of 5/10 with "no evidence" was passing, now requires 6+
RCE = 4
SQL = 6

# HIGH - Low threshold
XXE = 5
SSRF = 5
LFI = 5

# MEDIUM - Standard threshold  
XSS = 5
JWT = 6
FILE_UPLOAD = 6

# LOW RISK - Higher threshold
IDOR = 6

# Fallback for unknown types
DEFAULT = 5

[OPENROUTER]
# Enable online mode for models that support internet access.
# When True, passes the "online" parameter to OpenRouter API for web search/browsing capabilities.
# Required for agents to access external resources during reasoning.
ONLINE = True

[CONDUCTOR]
# Conductor V2 Anti-Hallucination System Configuration
# Enable/Disable Conductor V2 validation before emitting vulnerability findings.
# When True, findings are emitted without strict validation (for baseline testing / more findings).
# When False (default), all findings must pass through strict validation checks (reduces false positives).
DISABLE_VALIDATION = False

# Context refresh interval in seconds.
# Conductor V2 will reload protocol files periodically to prevent context drift.
# Recommended: 300 seconds (5 minutes) for scans > 10 minutes.
CONTEXT_REFRESH_INTERVAL = 300

# Minimum confidence threshold for findings (0.0 to 1.0).
# Findings below this threshold are automatically rejected.
# Default: 0.6 (60% confidence minimum)
MIN_CONFIDENCE = 0.6

# Enable/Disable false positive pattern detection.
# When True, findings matching known FP patterns are blocked.
ENABLE_FP_DETECTION = True

[BROWSER]
# Run the visual intelligence engine in headless mode (no window).
# Set to False if you want to see the crawler working in real-time.
HEADLESS = True

[BROWSER_ADVANCED]
# User Agent string to mimic legitimate traffic (Chrome/Windows).
USER_AGENT = Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36

# Browser Viewport dimensions.
VIEWPORT_WIDTH = 1280
VIEWPORT_HEIGHT = 720

# Generic navigation timeout in milliseconds.
TIMEOUT_MS = 15000

[CRAWLER]
# Wait time in milliseconds for SPA hydration (React/Vue/Angular rendering).
SPA_WAIT_MS = 1000

# Maximum internal queue size to prevent memory explosion.
MAX_QUEUE_SIZE = 100

# URL Extension Filtering
# Comma-separated list of extensions to EXCLUDE from analysis.
# These are static files that don't need vulnerability scanning.
EXCLUDE_EXTENSIONS = .js,.css,.jpg,.jpeg,.png,.gif,.svg,.ico,.woff,.woff2,.ttf,.eot,.pdf,.zip,.rar,.mp3,.mp4,.webm,.webp

# Only analyze URLs with these extensions (if empty, analyze all except excluded).
# Common web endpoints: .php,.asp,.aspx,.jsp,.html,.htm,.json,.xml
# Leave empty to analyze any URL not in EXCLUDE_EXTENSIONS
INCLUDE_EXTENSIONS = 

[SCAN]
# Maximum depth for the visual crawler (BFS).
MAX_DEPTH = 5

# Maximum number of unique URLs to scan.
MAX_URLS = 10

# Maximum concurrent URLMasterAgents (vertical agents per URL).
# Limits parallel processing to avoid API rate limits, memory issues, and costs.
# Recommended: 5-10 for most systems, up to 20 for powerful machines.
MAX_CONCURRENT_URL_AGENTS = 5

# GoSpider: Don't follow redirects.
# Useful to catch sensitive file leaks (.env, .htaccess, .git/config) that redirect
# to 403/404 but the original response may contain sensitive info BEFORE the redirect.
# Warning: May increase number of URLs found = more API calls = more cost.
# Default: False
GOSPIDER_NO_REDIRECT = False

# =============================================================================
# PARALLELIZATION - Granular Per-Phase Concurrency Control (v3.1)
# =============================================================================
# BugTraceAI uses phase-specific semaphores to control HOW MANY agents run
# simultaneously. Each running agent makes LLM calls independently (no global
# LLM semaphore - see LLM CONCURRENCY MODEL above).
#
# PHASE 1 - DISCOVERY:
#   GoSpider-based URL crawling. Single-threaded by design.
#
# PHASE 2 - ANALYSIS (DAST/SAST):
#   DASTySASTAgent analyzes URLs with 6 approaches (pentester, bug_bounty, etc.).
#   Each agent makes sequential LLM calls but multiple agents run in parallel.
#   WARNING: Values > 5 may cause execution hangs on some systems.
#
# PHASE 3 - EXPLOITATION (Specialists):
#   XSS, SQLi, CSTI, LFI, RCE, SSRF agents running in parallel.
#   Each specialist has its own worker pool processing queue items.
#   WARNING: High values may trigger WAF rate limits on target.
#
# PHASE 4 - VALIDATION:
#   CDP browser sessions + Vision LLM validation.
#   HARDCODED to 1 - CDP crashes with concurrent sessions.
# =============================================================================

[PARALLELIZATION]
# Discovery Phase - GoSpider crawling
# Range: 1-3, Default: 1 (GoSpider is single-threaded)
MAX_CONCURRENT_DISCOVERY = 1

# Analysis Phase - DASTySASTAgents analyzing URLs in parallel
# Range: 1-10, Recommended: 5 (higher values may cause hangs)
# Each agent makes LLM calls independently - no blocking between them
MAX_CONCURRENT_ANALYSIS = 5

# Exploitation Phase - Specialist agents (XSS, SQLi, CSTI, etc.)
# Range: 1-20, Recommended: 7-10
# Each specialist runs workers that process queue items in parallel
# WARNING: High values may trigger WAF rate limiting on target
MAX_CONCURRENT_SPECIALISTS = 7

# DAST Analysis Timeout - seconds per URL analysis (probes + LLM calls)
# Includes: HTTP probes + multiple LLM analysis calls
# Increase if you see timeout errors during analysis phase
DAST_ANALYSIS_TIMEOUT = 180.0

# NOTE: Validation Phase concurrency is HARDCODED to 1
# CDP (Chrome DevTools Protocol) crashes with concurrent sessions.
# This is NOT configurable - do not attempt to change it.

# =============================================================================
# URL PRIORITIZATION - Intelligent URL Ordering
# =============================================================================
# BugTraceAI scans high-value URLs first (admin, API, login) before low-priority
# ones. This maximizes impact in time-boxed scans and bug bounty contexts.
#
# Scoring system:
#   +10 points: Path contains high-value pattern (admin, api, login, upload...)
#   +5 points:  Parameter is sensitive (id, token, file, redirect, cmd...)
#   +15 points: URL has any parameters (bonus)
#   -20 points: Static file extension (.css, .js, .jpg, .png...)

[URL_PRIORITIZATION]
# Enable/disable URL prioritization (default: True)
ENABLED = True

# Log priority scores for each URL (default: True for debugging)
LOG_SCORES = True

# Custom high-priority paths (comma-separated, adds to defaults)
# Example: internal,backoffice,legacy
CUSTOM_PATHS =

# Custom high-priority parameters (comma-separated, adds to defaults)
# Example: tenant_id,org_id,workspace
CUSTOM_PARAMS =

# =============================================================================
# THINKING - ThinkingConsolidationAgent Configuration
# =============================================================================
# Controls how findings are filtered before reaching specialist agents.
# Lower FP_THRESHOLD = more findings forwarded (may include more false positives)
# Higher FP_THRESHOLD = stricter filtering (may miss edge cases like DOM XSS)

[THINKING]
# Minimum fp_confidence to forward findings to specialists (default: 0.3)
# DOM XSS typically has fp_confidence ~0.4, so 0.3 ensures they pass through
FP_THRESHOLD = 0.3

# Processing mode: "streaming" (real-time) or "batch" (grouped)
# MODE = streaming

# Max findings per batch in batch mode
# BATCH_SIZE = 50

# Max dedup keys to track (LRU eviction when exceeded)
# DEDUP_WINDOW = 1000

[SCANNING]
# Stop scan immediately when a critical vulnerability is validated.
# Critical = SQLi, RCE, XXE (full compromise)
# Saves tokens and time (1 SQLi = database already compromised)
STOP_ON_CRITICAL = False

# Vulnerability types that trigger scan stop.
# Comma-separated list: SQLi,RCE,XXE
CRITICAL_TYPES = SQLi,RCE,XXE

# Require SQLMap validation for ALL SQLi findings (mandatory).
# When True, NO SQLi finding is emitted without SQLMap confirmation.
# Prevents false positives (WAF blocks, generic errors).
MANDATORY_SQLMAP_VALIDATION = True

# Skip parameters already validated (avoid redundant scans).
# If cat=1 is SQLi, skip cat=2, cat=3, etc.
SKIP_VALIDATED_PARAMS = True

[ASSET_DISCOVERY]
# Enable/disable comprehensive asset discovery and subdomain enumeration.
# When True, the AssetDiscoveryAgent will:
#   - Enumerate subdomains (DNS bruteforce, Certificate Transparency)
#   - Discover hidden endpoints (Wayback Machine, common paths)
#   - Detect cloud storage (S3, Azure, GCP buckets)
# When False, only the provided target URL will be scanned.
# Set to False for faster scans focused on a specific URL.
# Set to True for comprehensive bug bounty reconnaissance.
ENABLE_ASSET_DISCOVERY = False

# Individual discovery method toggles (only applies if ENABLE_ASSET_DISCOVERY = True)
ENABLE_DNS_ENUMERATION = True
ENABLE_CERTIFICATE_TRANSPARENCY = True
ENABLE_WAYBACK_DISCOVERY = True
ENABLE_CLOUD_STORAGE_ENUM = True
ENABLE_COMMON_PATHS = True

# Maximum subdomains to test (prevents excessive API costs)
MAX_SUBDOMAINS = 50

[ANALYSIS]
# Multi-Model URL Analysis System
# Analyzes each URL with multiple LLM models before exploitation
# to identify likely vulnerabilities and reduce wasted testing.

# Enable/disable pre-exploitation analysis
ENABLE_ANALYSIS = True

# Models for different analysis personas
# Models for different analysis personas
PENTESTER_MODEL = x-ai/grok-4-fast
BUG_BOUNTY_MODEL = x-ai/grok-4-fast
AUDITOR_MODEL = x-ai/grok-4-fast

# Minimum confidence to attempt exploitation (0.0 - 1.0)
# Vulnerabilities below this threshold won't be tested
CONFIDENCE_THRESHOLD = 0.5

# Vulnerabilities below this threshold are skipped entirely
SKIP_THRESHOLD = 0.3

# Number of models required to agree for "consensus"
# 1 = highest sensitivity, 2 = more balanced, 3 = maximum precision
CONSENSUS_VOTES = 1

[PATHS]
# Directory where all scan logs (jsonl, errors) will be stored.
LOG_DIR = logs

# Directory where the final HTML vulnerability reports will be generated.
REPORT_DIR = reports

# ============================================================================
# VALIDATION - Vision-Based XSS Validation
# ============================================================================
[VALIDATION]
# Vision model for XSS screenshot validation (cost-conscious)
VISION_MODEL = google/gemini-3-flash-preview
VISION_ENABLED = True
VISION_ONLY_FOR_XSS = True
MAX_VISION_CALLS_PER_URL = 3

# ============================================================================
# REPORT - Report Generation Settings
# ============================================================================
[REPORT]
# Only include validated findings in the final report.
# When True: Report contains ONLY findings with evidence (validated=True)
# When False: Report includes both validated AND "Potential" findings
# Recommended: True for production (per report_quality_evaluation.md)
# "Missing Evidence = Invalid Finding"
ONLY_VALIDATED = False

[OPTIMIZATION]
# Early exit after first finding per URL.
# When True: Stop testing remaining params after first vuln found (70% faster)
# When False: Test ALL params for comprehensive audit coverage
# Recommended: True for bug bounty, False for full pentest audits
EARLY_EXIT_ON_FINDING = False

# =============================================================================
# ADAPTIVE PAYLOADS - Q-Learning WAF Bypass System
# =============================================================================
# BugTraceAI uses a Multi-Armed Bandit (UCB1) algorithm to learn which
# encoding strategies work best against each WAF type. The system:
#
# 1. FINGERPRINTS the WAF (Cloudflare, ModSecurity, AWS WAF, Akamai, etc.)
# 2. SELECTS encoding strategies based on past success rates
# 3. MUTATES payloads using LLM-powered transformations
# 4. LEARNS from results and improves over time
#
# Learning data persists in: bugtrace/data/waf_strategy_learning.json
# This means BugTraceAI gets SMARTER with each scan.
#
# =============================================================================

[WAF_BYPASS]
# -------------------------------------------------------------------------
# WAF Detection Models
# -------------------------------------------------------------------------
# Models used to analyze WAF signatures and identify blocking patterns.
# Multiple models provide consensus for accurate WAF identification.
# Configured in [LLM_MODELS] section: WAF_DETECTION_MODELS

# -------------------------------------------------------------------------
# Mutation Model
# -------------------------------------------------------------------------
# Model for payload mutation and WAF bypass generation.
# DeepSeek recommended: fewer safety restrictions for security research.
# Configured in [LLM_MODELS] section: MUTATION_MODEL

# -------------------------------------------------------------------------
# Supported WAF Types (Auto-detected)
# -------------------------------------------------------------------------
# The fingerprinter automatically detects:
#   - cloudflare    : Cloudflare WAF (ray-id headers, challenge pages)
#   - modsecurity   : ModSecurity/OWASP CRS (error patterns)
#   - aws_waf       : AWS WAF (x-amzn headers, 403 patterns)
#   - akamai        : Akamai Kona (reference IDs, edge headers)
#   - imperva       : Imperva Incapsula (visid cookies, headers)
#   - f5_bigip      : F5 BIG-IP ASM (TS cookies, headers)
#   - sucuri        : Sucuri WAF (x-sucuri headers)
#   - fortiweb      : FortiWeb (fortigate cookies)
#   - nginx_naxsi   : NAXSI (block patterns)
#   - barracuda     : Barracuda WAF (barra cookies)
#   - generic       : Unknown WAF (fallback strategies)

# -------------------------------------------------------------------------
# Encoding Strategies (Auto-selected by Q-Learning)
# -------------------------------------------------------------------------
# Available encoding techniques that the system learns to use:
#
# BASIC ENCODINGS:
#   - url_encode           : Standard %XX encoding
#   - double_url_encode    : Double encoding (%25XX)
#   - unicode_encode       : Unicode escapes (\uXXXX)
#   - html_entity_encode   : HTML entities (&lt; &gt;)
#   - html_entity_hex      : Hex HTML entities (&#x3C;)
#   - base64_encode        : Base64 encoding
#
# ADVANCED EVASIONS:
#   - case_mixing          : MiXeD CaSe (bypasses case-sensitive rules)
#   - null_byte_injection  : %00 injection (truncates strings)
#   - comment_injection    : SQL/JS comments (/**/,--)
#   - whitespace_obfuscation : Tabs, newlines, exotic spaces
#   - overlong_utf8        : Overlong UTF-8 sequences
#   - backslash_escape     : Backslash escaping
#
# SQL-SPECIFIC:
#   - concat_string        : CONCAT(), || operators
#   - hex_encode           : 0x encoding for strings
#   - scientific_notation  : 1e0 instead of 1
#
# BUFFER/INJECTION:
#   - buffer_overflow      : Long strings to overflow buffers
#   - newline_injection    : CR/LF injection

[QLEARNING]
# -------------------------------------------------------------------------
# Q-Learning Hyperparameters
# -------------------------------------------------------------------------
# These control how the system balances exploration (trying new strategies)
# vs exploitation (using known good strategies).

# Initial exploration rate (epsilon).
# Higher = more random exploration at start.
# Range: 0.0-1.0, Default: 0.3 (30% exploration initially)
INITIAL_EPSILON = 0.3

# Minimum exploration rate.
# Even after learning, maintain some exploration to discover new bypasses.
# Range: 0.0-1.0, Default: 0.05 (always 5% exploration)
MIN_EPSILON = 0.05

# Epsilon decay rate per episode.
# How fast exploration decreases as system learns.
# Range: 0.9-0.999, Default: 0.995 (slow decay, thorough learning)
DECAY_RATE = 0.995

# UCB1 exploration constant (c).
# Higher = more exploration of uncertain strategies.
# Range: 0.5-4.0, Default: 2.0 (balanced exploration/exploitation)
# Formula: UCB = success_rate + c * sqrt(ln(total) / attempts)
UCB_CONSTANT = 2.0

# Maximum Q-table backups to keep.
# System auto-backs up learning data before modifications.
# Range: 1-20, Default: 5
MAX_BACKUPS = 5

# -------------------------------------------------------------------------
# How Q-Learning Works in BugTraceAI
# -------------------------------------------------------------------------
#
# 1. WAF DETECTION:
#    - Sends probe request to target
#    - Analyzes response headers, cookies, error pages
#    - Identifies WAF type (or "generic" if unknown)
#
# 2. STRATEGY SELECTION (UCB1 Algorithm):
#    - Loads learning data for detected WAF
#    - Calculates UCB score for each encoding strategy:
#      UCB = success_rate + c * sqrt(ln(total_attempts) / strategy_attempts)
#    - Selects strategy with highest UCB (balances known-good vs unexplored)
#
# 3. PAYLOAD MUTATION:
#    - Takes base payload (e.g., <script>alert(1)</script>)
#    - Applies selected encoding strategy
#    - Optionally uses LLM (MUTATION_MODEL) for intelligent mutations
#    - Generates multiple variants
#
# 4. TESTING & LEARNING:
#    - Tests encoded payloads against target
#    - Records success/failure for each strategy
#    - Updates Q-table (waf_strategy_learning.json)
#    - Next scan benefits from learned knowledge
#
# EXAMPLE LEARNING PROGRESSION:
#   Scan 1: Cloudflare detected, tries all strategies randomly
#   Scan 2: Knows double_url_encode worked, prioritizes it
#   Scan 3: double_url_encode blocked, tries unicode_encode
#   Scan 4: Learns Cloudflare blocks both, tries case_mixing
#   ...
#   Scan N: Has optimal strategy ranking for Cloudflare
#
# -------------------------------------------------------------------------
# Viewing Learning Data
# -------------------------------------------------------------------------
# The Q-table is stored in: bugtrace/data/waf_strategy_learning.json
#
# Example content:
# {
#   "cloudflare": {
#     "strategies": {
#       "double_url_encode": {"attempts": 15, "successes": 12},
#       "unicode_encode": {"attempts": 10, "successes": 3},
#       "case_mixing": {"attempts": 8, "successes": 7}
#     }
#   }
# }
#
# Success rate = successes / attempts
# Higher success rate = strategy used more often for that WAF
#
# -------------------------------------------------------------------------

[AUTHORITY]
# Allow specialist agents to self-validate findings if confidence is high.
# If True, agents can mark findings as VALIDATED_CONFIRMED based on their own evidence
# (e.g., SQLMap confirmation, XSS execution proof), skipping the secondary Auditor phase.
# If False, ALL findings go to 'Pending Validation' for independent verification.
ENABLE_SELF_VALIDATION = True

# Specific overrides per agent type
XSS_SELF_VALIDATE = True
SQLI_SELF_VALIDATE = True
RCE_SELF_VALIDATE = True

# =============================================================================
# MANIPULATOR - HTTP Exploitation Tool (Intelligent Breakouts System)
# =============================================================================
[MANIPULATOR]
# Global rate limiting across ALL ManipulatorOrchestrator instances.
# When XSSSkill and CSTISkill run in parallel, this ensures they don't saturate targets.
# Default: 2.0 req/s total (shared between XSS + CSTI)
GLOBAL_RATE_LIMIT = 2.0

# Use global rate limiter (coordinates requests across XSS/CSTI)
# If False, each skill uses independent rate limiting
USE_GLOBAL_RATE_LIMITER = True

# Enable LLM-powered payload expansion (Phase 1b)
# Generates 100 base payloads with DeepSeek, expands with breakouts
ENABLE_LLM_EXPANSION = True

# Enable agentic fallback (Phase 3) - Future implementation
ENABLE_AGENTIC_FALLBACK = False

# Breakout priority level (1=critical, 2=high, 3=normal, 4=advanced)
# Lower = faster scans, higher = more coverage
BREAKOUT_PRIORITY_LEVEL = 3

# Maximum LLM-generated base payloads
MAX_LLM_PAYLOADS = 100

# =============================================================================
# LONEWOLF - Autonomous Exploration Agent
# =============================================================================
# The LoneWolf runs in parallel with the pipeline (Phases 2-5) using only
# raw HTTP + LLM reasoning to explore the target independently.
# It finds vulnerabilities the structured pipeline might miss.
# Findings are deduplicated against specialist findings automatically.

[ANTHROPIC]
# Direct Anthropic API via OAuth â€” $0 on Claude Pro/Max plan.
# 1. Run: bash tools/anthropic_login.sh
# 2. Set ENABLED = True below
# 3. The wizard will update model names with anthropic/ prefix automatically
ENABLED = False
# TOKEN_FILE = ~/.bugtrace/auth.json

[LONEWOLF]
# Enable/disable the autonomous exploration agent
ENABLED = True

# OpenRouter model for reasoning. Needs to be reliable and produce clean output.
# The wolf uses this model for ALL its reasoning - choosing what to explore,
# analyzing responses, deciding what payloads to test
MODEL = moonshotai/kimi-k2.5

# HTTP request rate limit (requests per second to target)
# At 1.0 req/s over a 1-hour scan, the wolf makes ~3600 requests
# This is negligible compared to the pipeline's thousands
RATE_LIMIT = 1.0

# Sliding window size for context (number of recent actions remembered)
# Higher = more context for LLM = better reasoning but more tokens
MAX_CONTEXT = 20

# Max characters to keep from HTTP responses (truncation)
# Keeps LLM prompts manageable while preserving enough for analysis
RESPONSE_TRUNCATE = 2000
