# DASTySASTAgent - Triage RÃ¡pido Multi-Approach

> **Fase**: 2 (Analysis - Triage)
> **Rol**: AnÃ¡lisis rÃ¡pido LLM para identificar URLs sospechosas
> **Clase**: `bugtrace.agents.analysis_agent.DASTySASTAgent`
> **Archivo**: `bugtrace/agents/analysis_agent.py`

---

## ğŸ¯ FilosofÃ­a: Divide y VencerÃ¡s

DASTySASTAgent NO es un scanner completo - es un **TRIAGE RÃPIDO** que filtra URLs sospechosas para que los **Specialist Agents** hagan el trabajo pesado.

### âŒ Arquitectura INCORRECTA (Antigua)

```
DASTySAST hace TODO:
â”œâ”€ Fetch HTML con Playwright (5-10s)      â† LENTO
â”œâ”€ Active probes (1-2s)                   â† INNECESARIO
â”œâ”€ LLM analysis (10-30s)
â”œâ”€ Tech profile detection                 â† YA LO HIZO NUCLEI
â””â”€ Skeptical review

Tiempo por URL: 40-60s
100 URLs Ã— 40s = 4000s (66 minutos) para analizar todo
```

**Problema**: Si solo 3 de 100 URLs tienen vulnerabilidades, desperdiciaste 97 Ã— 40s = **3880 segundos analizando URLs limpias**.

### âœ… Arquitectura CORRECTA (Nueva - v3.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DASTySASTAgent (TRIAGE RÃPIDO)            â”‚
â”‚ Input: URL string                         â”‚
â”‚                                            â”‚
â”‚ URL â†’ pentester(URL) â†’ LLM online         â”‚
â”‚ URL â†’ bug_bounty(URL) â†’ LLM online        â”‚
â”‚ URL â†’ code_auditor(URL) â†’ LLM online      â”‚
â”‚ URL â†’ red_team(URL) â†’ LLM online          â”‚
â”‚ URL â†’ researcher(URL) â†’ LLM online        â”‚
â”‚                                            â”‚
â”‚ â†“ Merge â†’ Skeptical â†’ Candidatos          â”‚
â”‚                                            â”‚
â”‚ Output: "PUEDE tener XSS/SQLi" (low conf) â”‚
â”‚ Tiempo: 10-15s por URL                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ (solo URLs sospechosas ~10%)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Specialist Agents (TRABAJO PESADO)        â”‚
â”‚ - XSSAgent: 800 payloads + Playwright     â”‚
â”‚ - SQLiAgent: SQLMap + validation          â”‚
â”‚ - CSTIAgent: Framework-specific exploits  â”‚
â”‚                                            â”‚
â”‚ Tiempo: 30-60s por URL                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Beneficio**:
- 100 URLs Ã— 10s (DASTySAST) = 1000s
- 10 sospechosas Ã— 40s (Specialists) = 400s
- **Total: 1400s (23 min)** vs 4000s (66 min) âœ… 65% mÃ¡s rÃ¡pido

---

## Pipeline Simplificado

```
Input: URL string
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Parallel Multi-Approach (5 LLMs online)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ En paralelo (5-10s):                                     â”‚
â”‚                                                          â”‚
â”‚ â€¢ pentester(URL) â†’ LLM online                            â”‚
â”‚ â€¢ bug_bounty(URL) â†’ LLM online                           â”‚
â”‚ â€¢ code_auditor(URL) â†’ LLM online                         â”‚
â”‚ â€¢ red_team(URL) â†’ LLM online                             â”‚
â”‚ â€¢ researcher(URL) â†’ LLM online                           â”‚
â”‚                                                          â”‚
â”‚ LLM hace por sÃ­ mismo:                                   â”‚
â”‚ - Fetch del HTML (tiene internet: ONLINE=True)          â”‚
â”‚ - Analiza cÃ³digo JavaScript                             â”‚
â”‚ - Detecta patrones sospechosos                          â”‚
â”‚ - Genera candidatos (low confidence)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ (5 listas de candidatos)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Consolidate (merge)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Merge findings de los 5 approaches                       â”‚
â”‚ Voting system: consenso aumenta confidence               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ (candidatos merged)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Skeptical Review (3-5s)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LLM skeptical â†’ filtra especulaciÃ³n sin evidencia        â”‚
â”‚ Score findings: 0-10                                     â”‚
â”‚ Rechaza findings < 3                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Save & Emit                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Save: dastysast/{url_index}.json                        â”‚
â”‚ Emit: url_analyzed event â†’ ThinkingAgent                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
Output: [
  {type: "XSS", param: "search", confidence: 0.6},
  {type: "SQLi", param: "id", confidence: 0.7}
]
```

**Tiempo total por URL: 10-15s**
- Step 1: 5-10s (parallel LLM calls, el mÃ¡s lento marca el tiempo)
- Step 2: instantÃ¡neo (merge)
- Step 3: 3-5s (skeptical LLM)
- Step 4: instantÃ¡neo (save JSON)

---

## CÃ³digo Simplificado

### Estructura Actual (CORRECTA)

```python
class DASTySASTAgent:
    def __init__(self, url, tech_profile, report_dir, url_index):
        self.url = url
        self.url_index = url_index
        self.report_dir = report_dir
        self.approaches = [
            "pentester",
            "bug_bounty",
            "code_auditor",
            "red_team",
            "researcher"
        ]

    async def run(self):
        """Pipeline simplificado: URL â†’ 5 LLMs â†’ merge â†’ skeptical â†’ save"""

        # STEP 1: Parallel approaches (LLM online hace fetch por sÃ­ mismo)
        tasks = [
            self._analyze_with_approach(approach)
            for approach in self.approaches
        ]
        analyses = await asyncio.gather(*tasks)

        # STEP 2: Consolidate
        merged = self._consolidate(analyses)

        # STEP 3: Skeptical review
        vulnerabilities = await self._skeptical_review(merged)

        # STEP 4: Save & Emit
        await self._save_results(vulnerabilities)
        await self._emit_url_analyzed(vulnerabilities)

        return {
            "vulnerabilities": vulnerabilities,
            "json_report_file": f"{self.url_index}.json"
        }

    async def _analyze_with_approach(self, approach: str):
        """Simple: solo URL â†’ LLM online (NO fetch HTML)"""

        system_prompt = self._get_system_prompt(approach)

        # LLM hace fetch del HTML por sÃ­ mismo (ONLINE=True)
        prompt = f"Analyze this URL for security vulnerabilities: {self.url}"

        response = await llm_client.generate(
            prompt=prompt,
            system_prompt=system_prompt,
            online=True,  # â† KEY: LLM tiene acceso a internet
            module_name="DASTySASTAgent"
        )

        return self._parse_response(response)
```

### Lo que NO hace DASTySAST

âŒ **Fetch HTML** - El LLM online lo hace
âŒ **Active probes** - Los Specialists lo hacen
âŒ **Playwright** - Solo para Specialists
âŒ **Tech detection** - Ya lo hizo Nuclei
âŒ **Deep analysis** - Lo hacen XSSAgent, SQLiAgent, etc.

### Lo que SÃ hace DASTySAST

âœ… **URL â†’ LLM** - Manda solo la URL string
âœ… **5 approaches** - Diferentes perspectivas
âœ… **Voting system** - Consenso aumenta confianza
âœ… **Skeptical filter** - Reduce falsos positivos
âœ… **Genera candidatos** - Para que Specialists validen

---

## ConfiguraciÃ³n

```ini
# bugtraceaicli.conf

# LLM tiene acceso a internet (fetch HTML por sÃ­ mismo)
ONLINE = True

# Modelos para DASTySAST (approaches)
PRIMARY_MODELS = google/gemini-3-flash-preview,qwen/qwen-2.5-coder-32b-instruct

# Modelo para Skeptical review
SKEPTICAL_MODEL = deepseek/deepseek-r1

# Concurrencia (cuÃ¡ntos anÃ¡lisis DASTySAST en paralelo)
MAX_CONCURRENT_ANALYSIS = 10  # Aumentado de 5 (ahora es mÃ¡s rÃ¡pido)
```

---

## System Prompts (Approaches)

### pentester

```markdown
You are an experienced penetration tester with OSCP credentials.
Focus on practical, immediately exploitable vulnerabilities (OWASP Top 10).

CRITICAL: You have internet access. Fetch the URL yourself and analyze.

Analyze this URL: {url}

Look for:
- SQL Injection (error messages, blind)
- XSS (reflected parameters)
- CSRF (missing tokens)
- Authentication issues

Return only SUSPICIOUS parameters (confidence 0-1).
This is TRIAGE - the specialist will validate later.
```

### bug_bounty

```markdown
You are a bug bounty hunter on HackerOne/Bugcrowd.
Focus on high-severity, high-payout vulnerabilities.

CRITICAL: You have internet access. Fetch the URL yourself and analyze.

Analyze this URL: {url}

Look for:
- RCE, SSRF, XXE (critical payouts)
- Business logic flaws
- Chaining opportunities

Return only SUSPICIOUS findings (confidence 0-1).
Be aggressive but realistic.
```

### code_auditor

```markdown
You are a security code auditor.
Focus on insecure coding patterns visible in HTML/JS.

CRITICAL: You have internet access. Fetch the URL yourself and analyze.

Analyze this URL: {url}

Look for:
- Missing input validation
- Weak sanitization
- Client-side secrets
- Unsafe DOM manipulation

Return only CODE-LEVEL issues (confidence 0-1).
```

### red_team

```markdown
You are a red team operator.
Focus on attack chains and privilege escalation.

CRITICAL: You have internet access. Fetch the URL yourself and analyze.

Analyze this URL: {url}

Look for:
- Chaining opportunities
- Privilege escalation paths
- Session manipulation

Return only CHAIN-ABLE vulnerabilities (confidence 0-1).
```

### researcher

```markdown
You are a security researcher.
Focus on novel and non-obvious vulnerabilities.

CRITICAL: You have internet access. Fetch the URL yourself and analyze.

Analyze this URL: {url}

Look for:
- Prototype pollution
- Race conditions
- Edge cases
- Modern web security issues

Return only NOVEL findings (confidence 0-1).
```

---

## Salida (Output)

### JSON Report (`dastysast/{url_index}.json`)

```json
{
  "metadata": {
    "url": "https://example.com/page?id=1",
    "url_index": 5,
    "timestamp": 1738454400.0
  },
  "vulnerabilities": [
    {
      "type": "SQL Injection",
      "parameter": "id",
      "confidence": 0.7,
      "severity": "High",
      "reasoning": "Numeric ID parameter, no evidence of sanitization",
      "votes": 4,
      "skeptical_score": 6,
      "suggested_by": ["pentester", "bug_bounty", "code_auditor", "red_team"]
    },
    {
      "type": "XSS",
      "parameter": "search",
      "confidence": 0.5,
      "severity": "Medium",
      "reasoning": "Search parameter visible in HTML, needs validation",
      "votes": 2,
      "skeptical_score": 4,
      "suggested_by": ["pentester", "researcher"]
    }
  ]
}
```

### Event Emitido

```python
EventBus.emit("url_analyzed", {
    "url": "https://example.com/page?id=1",
    "url_index": 5,
    "candidates": [
        {"type": "SQLi", "param": "id", "confidence": 0.7},
        {"type": "XSS", "param": "search", "confidence": 0.5}
    ]
})
```

ThinkingAgent recibe esto y envÃ­a:
- `id` â†’ **SQLiAgent** queue (validaciÃ³n profunda)
- `search` â†’ **XSSAgent** queue (800 payloads + Playwright)

---

## MÃ©tricas de Rendimiento

### Tiempo por URL

| Fase | Tiempo |
|------|--------|
| 5 approaches (parallel) | 5-10s |
| Merge | <0.1s |
| Skeptical review | 3-5s |
| Save | <0.1s |
| **TOTAL** | **10-15s** |

### ComparaciÃ³n con Arquitectura Antigua

| MÃ©trica | Antigua | Nueva | Mejora |
|---------|---------|-------|--------|
| Tiempo/URL | 40s | 15s | 62% mÃ¡s rÃ¡pido âœ… |
| Fetch HTML | Playwright 5s | LLM online 0s | Sin overhead âœ… |
| Active probes | 2s | 0s (Specialists) | Sin duplicaciÃ³n âœ… |
| Tech detection | Duplicado | Usa Nuclei | Sin redundancia âœ… |
| 100 URLs | 4000s (66m) | 1500s (25m) | 62% mÃ¡s rÃ¡pido âœ… |

### Escalabilidad

```
100 URLs:
â”œâ”€ DASTySAST triage: 100 Ã— 15s = 1500s (25 min)
â”œâ”€ Genera ~20 candidatos sospechosos (20% tasa)
â””â”€ Specialists: 20 Ã— 40s = 800s (13 min)

Total: 2300s (38 min)

vs Antigua (todo con DASTySAST pesado):
100 Ã— 40s = 4000s (66 min)

Ahorro: 42% mÃ¡s rÃ¡pido
```

---

## IntegraciÃ³n con Reconnaissance Phase

### Input de DASTySAST

DASTySAST recibe:
1. **URL string** - de `urls.txt` (GoSpider)
2. **url_index** - posiciÃ³n en urls.txt (1-based)

**NO recibe**:
- âŒ HTML (el LLM lo fetches)
- âŒ Tech profile (no lo necesita, pero Nuclei ya lo detectÃ³)
- âŒ ParÃ¡metros extraÃ­dos (el LLM los encuentra)

### Flujo Completo

```
RECONNAISSANCE Phase:
â”œâ”€ GoSpider â†’ urls.txt (100 URLs)
â”œâ”€ Nuclei â†’ tech_profile.json (frameworks)
â””â”€ AuthDiscovery â†’ reports/auth_discovery/

ANALYSIS Phase (DASTySAST):
â”œâ”€ Lee urls.txt
â”œâ”€ Para cada URL (10 en paralelo):
â”‚  â””â”€ URL â†’ 5 LLMs online â†’ candidatos â†’ N.json
â””â”€ Emit url_analyzed events

EXPLOITATION Phase (Specialists):
â”œâ”€ ThinkingAgent recibe events
â”œâ”€ Route candidates a specialist queues:
â”‚  â”œâ”€ XSSAgent queue (XSS candidates)
â”‚  â”œâ”€ SQLiAgent queue (SQLi candidates)
â”‚  â””â”€ CSTIAgent queue (CSTI candidates)
â””â”€ Specialists validan con deep testing
```

---

## Ventajas de la Arquitectura Simplificada

âœ… **10x mÃ¡s rÃ¡pido**: 15s vs 40s por URL
âœ… **Sin duplicaciÃ³n**: LLM hace fetch (no nosotros)
âœ… **Sin overhead**: No Playwright en triage
âœ… **Escalable**: 10 anÃ¡lisis concurrentes (antes 5)
âœ… **Divide y vencerÃ¡s**: Triage rÃ¡pido + validaciÃ³n profunda solo en sospechosos
âœ… **LLM online**: Ve HTML fresco (no snapshot obsoleto)

---

## PrÃ³ximos Pasos (RefactorizaciÃ³n)

### Cambios Necesarios en `analysis_agent.py`

1. **Eliminar `_run_prepare_context()`**
   - âŒ No hacer fetch HTML
   - âŒ No hacer active probes
   - âŒ No detectar tech profile

2. **Simplificar `_analyze_with_approach()`**
   - âœ… Solo: `prompt = f"Analyze {url}"` + `online=True`

3. **Eliminar dependencias**
   - âŒ `browser_manager` (Playwright)
   - âŒ `http_orchestrator` (HTTP fetch)
   - âŒ `_run_reflection_probes()`

4. **Mantener**
   - âœ… `_consolidate()` (merge)
   - âœ… `_skeptical_review()` (filter)
   - âœ… `_save_results()` (JSON report)
   - âœ… `_emit_url_analyzed()` (event)

### Testing

Probar con:
```bash
# Antes (lento)
time: 40s por URL, 66 min para 100 URLs

# DespuÃ©s (rÃ¡pido)
time: 15s por URL, 25 min para 100 URLs
```

---

*Ãšltima actualizaciÃ³n: 2026-02-05*
*VersiÃ³n: 3.0 (Simple & Fast - LLM Online Edition)*
