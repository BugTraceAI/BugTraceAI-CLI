import asyncio
import json
import os
from pathlib import Path
from bugtrace.agents.reporting import ReportingAgent

async def regenerate_report(base_report_dir: str):
    """
    Manually regenerates the full report from partial analysis files.
    """
    report_path = Path(base_report_dir)
    if not report_path.exists():
        print(f"Error: Directory {report_path} not found.")
        return

    print(f"ğŸ” Scanning {report_path} for findings...")
    
    all_findings = []
    
    # 1. Load Tech Profile if exists
    tech_profile = {}
    try:
        with open(report_path / "recon/tech_profile.json", "r") as f:
            tech_profile = json.load(f)
    except:
        pass

    target_url = tech_profile.get("url", "https://ginandjuice.shop/")
    
    # 2. Extract findings from analysis folders
    analysis_dir = report_path / "analysis"
    if analysis_dir.exists():
        for subdir in analysis_dir.iterdir():
            if subdir.is_dir():
                # Check for vulnerability markdown files
                for file in subdir.glob("vulnerabilities_*.md"):
                    print(f"  -> Found report fragment: {file.name}")
                    # In a real scenario, we would parse the markdown back to JSON 
                    # but for now, we will look for any accompanying .json metadata if it exists
                    # OR simply trigger the reporting agent to 'glob' these markdowns.
                    
                    # Since ReportingAgent.generate_final_report expects a list of Dict findings,
                    # we will attempt to extract basic info from the markdown filename if JSON is missing.
                    # Ideally, the agents save a .json alongside the .md
                    pass

    # NOTE: The current architecture saves findings to DB or relies on them being passed in memory.
    # Since the crash lost memory state, we might rely on what's on disk.
    # Let's check if there are any .json finding files.
    
    # Strategy B: Re-read logs to reconstruct findings (Advanced)
    # Strategy C: Just run ReportingAgent which might have a "scan_dir" mode?
    # Actually, ReportingAgent usually takes 'findings' list.
    
    # Let's try to mock some findings based on the filenames we see, 
    # OR better, if we have a database, query it.
    
    print("âš ï¸  Reconstruction from disk artifacts (Partial capability)...")
    
    # Mocking findings based on file existence (since we saw them in the `ls` output)
    # policies:
    # url_https_ginandjuice.shop_blog_post_postId__d2e4a530 -> vulnerabilities_...postId_3.md
    
    recovered_findings = []
    
    # Walk and read MD content to look for "CONFIRMED" or Evidence
    for md_file in analysis_dir.rglob("*.md"):
        content = md_file.read_text()
        if "Severity: High" in content or "Severity: Critical" in content:
            # Simple parser to recover basic finding
             recovered_findings.append({
                 "type": "Recovered Vulnerability",
                 "url": target_url,  # Approximation
                 "severity": "High",
                 "description": f"Recovered finding from {md_file.name}. Please check file for details.",
                 "evidence": {"file_path": str(md_file)},
                 "validated": True
             })
    
    print(f"âœ… Recovered {len(recovered_findings)} findings from disk.")

    # 3. Generate Report
    agent = ReportingAgent(target_url)
    await agent.generate_final_report(
        recovered_findings,
        [target_url],
        tech_profile,
        report_path
    )
    print("ğŸ‰ Report regeneration complete!")

if __name__ == "__main__":
    import sys
    target_dir = sys.argv[1] if len(sys.argv) > 1 else "reports/ginandjuice.shop_20260113_134720"
    asyncio.run(regenerate_report(target_dir))
